<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Groklexa</title>
    <!-- ONNX Runtime for wake word detection -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/onnxruntime-web/1.22.0/ort.wasm.min.js"></script>
    <!-- Lucide Icons -->
    <script src="https://unpkg.com/lucide@latest/dist/umd/lucide.min.js"></script>
    <!-- Elegant font -->
    <link href="https://fonts.googleapis.com/css2?family=Cormorant+Garabald:ital,wght@0,300;0,400;0,500;0,600;1,300;1,400&family=Raleway:wght@300;400;500;600&display=swap" rel="stylesheet">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        :root {
            --cream: #d6cdbc;
            --cream-light: #e5ded0;
            --cream-dark: #c7bead;
            --warm-gray: #8a8075;
            --warm-brown: #5c5347;
            --accent: #9c8b7a;
            --accent-light: #c4b8aa;
            --text-dark: #3d3530;
            --text-muted: #7a716a;
            --glass-bg: rgba(255, 252, 248, 0.7);
            --glass-border: rgba(255, 255, 255, 0.4);
            --shadow-soft: rgba(107, 94, 82, 0.1);
        }
        
        /* Night Mode */
        [data-theme="night"] {
            --cream: #0a0a0f;
            --cream-light: #000000;
            --cream-dark: #0a0a0f;
            --warm-gray: #6a6a80;
            --warm-brown: #9090a8;
            --accent: #667eea;
            --accent-light: #5a67d8;
            --text-dark: #e8e8f0;
            --text-muted: #a0a0b8;
            --glass-bg: rgba(10, 10, 15, 0.9);
            --glass-border: rgba(102, 126, 234, 0.3);
            --shadow-soft: rgba(0, 0, 0, 0.5);
        }
        
        /* Night mode video pane - pure black */
        [data-theme="night"] .video-pane {
            background: #000000;
        }
        
        /* Night mode form controls */
        [data-theme="night"] .voice-selector select {
            background-color: rgba(20, 20, 30, 0.9);
            border-color: var(--accent-light);
            color: var(--text-dark);
            background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='12' height='12' viewBox='0 0 12 12'%3E%3Cpath fill='%23a0a0b8' d='M6 8L1 3h10z'/%3E%3C/svg%3E");
            background-repeat: no-repeat;
            background-position: right 16px center;
        }
        
        [data-theme="night"] .voice-selector select:hover {
            background: rgba(30, 30, 45, 0.95);
            border-color: var(--accent);
        }
        
        [data-theme="night"] .vad-toggle {
            background: rgba(20, 20, 30, 0.8);
        }
        
        [data-theme="night"] .slider {
            background: rgba(40, 40, 60, 0.9);
            border-color: var(--accent-light);
        }
        
        body {
            font-family: 'Raleway', sans-serif;
            background: linear-gradient(135deg, var(--cream) 0%, var(--cream-dark) 100%);
            min-height: 100vh;
            display: flex;
            color: var(--text-dark);
        }
        
        .main-container {
            display: flex;
            width: 100%;
            min-height: 100vh;
        }
        
        /* Left Pane - Video */
        .video-pane {
            width: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            background: linear-gradient(180deg, var(--cream-light) 0%, var(--cream) 100%);
            position: relative;
            overflow: hidden;
        }
        
        .video-container {
            width: 100%;
            height: 100%;
            display: flex;
            align-items: center;
            justify-content: center;
            padding: 40px;
        }
        
        #groklexaVideo {
            max-width: 100%;
            max-height: 90vh;
            border-radius: 20px;
            box-shadow: 0 30px 80px var(--shadow-soft), 0 10px 30px rgba(0,0,0,0.08);
            object-fit: contain;
        }
        
        /* Right Pane - Controls */
        .controls-pane {
            width: 50%;
            padding: 60px 50px;
            display: flex;
            flex-direction: column;
            justify-content: center;
            background: var(--cream);
            overflow-y: auto;
        }
        
        .controls-inner {
            max-width: 480px;
            margin: 0 auto;
            width: 100%;
        }
        
        h1 {
            font-family: 'Cormorant Garamond', serif;
            font-size: 3.5rem;
            font-weight: 300;
            color: var(--text-dark);
            margin-bottom: 8px;
            letter-spacing: 0.02em;
            text-align: center;
        }
        
        .subtitle {
            font-family: 'Cormorant Garamond', serif;
            font-size: 1.2rem;
            font-style: italic;
            color: var(--text-muted);
            margin-bottom: 30px;
            font-weight: 300;
            text-align: center;
        }
        
        
        /* Glass Card Style */
        .glass-card {
            background: var(--glass-bg);
            backdrop-filter: blur(10px);
            -webkit-backdrop-filter: blur(10px);
            border: 1px solid var(--glass-border);
            border-radius: 16px;
            padding: 25px;
            margin-bottom: 25px;
        }
        
        /* Voice Selector */
        .voice-selector label {
            display: block;
            margin-bottom: 10px;
            color: var(--text-muted);
            font-weight: 500;
            font-size: 0.9rem;
            text-transform: uppercase;
            letter-spacing: 0.1em;
        }
        
        .voice-selector select {
            width: 100%;
            padding: 14px 18px;
            border: 1px solid var(--accent-light);
            border-radius: 10px;
            font-size: 1rem;
            background: rgba(255, 255, 255, 0.6);
            color: var(--text-dark);
            cursor: pointer;
            transition: all 0.3s ease;
            font-family: 'Raleway', sans-serif;
            appearance: none;
            background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='12' height='12' viewBox='0 0 12 12'%3E%3Cpath fill='%236b5e52' d='M6 8L1 3h10z'/%3E%3C/svg%3E");
            background-repeat: no-repeat;
            background-position: right 16px center;
        }
        
        .voice-selector select:hover {
            border-color: var(--accent);
            background-color: rgba(255, 255, 255, 0.8);
        }
        
        .voice-selector select:focus {
            outline: none;
            border-color: var(--warm-brown);
            box-shadow: 0 0 0 3px rgba(156, 139, 122, 0.2);
        }
        
        /* Buttons */
        .btn-row {
            display: flex;
            gap: 12px;
            margin-bottom: 20px;
        }
        
        button {
            padding: 14px 24px;
            font-size: 0.95rem;
            font-weight: 500;
            border: 1px solid var(--glass-border);
            border-radius: 12px;
            cursor: pointer;
            transition: all 0.3s ease;
            font-family: 'Raleway', sans-serif;
            letter-spacing: 0.05em;
            backdrop-filter: blur(10px);
            -webkit-backdrop-filter: blur(10px);
        }
        
        .btn-primary {
            background: linear-gradient(135deg, rgba(76, 175, 80, 0.8) 0%, rgba(102, 187, 106, 0.9) 100%);
            color: white;
            border-color: rgba(76, 175, 80, 0.3);
            flex: 1;
        }
        
        .btn-primary:hover:not(:disabled) {
            background: linear-gradient(135deg, rgba(76, 175, 80, 0.95) 0%, rgba(102, 187, 106, 1) 100%);
            transform: translateY(-2px);
            box-shadow: 0 8px 25px rgba(76, 175, 80, 0.3);
        }
        
        .btn-secondary {
            background: linear-gradient(135deg, rgba(156, 139, 122, 0.7) 0%, rgba(138, 128, 117, 0.8) 100%);
            color: white;
            border-color: rgba(156, 139, 122, 0.3);
            flex: 1;
        }
        
        .btn-secondary:hover:not(:disabled) {
            background: linear-gradient(135deg, rgba(156, 139, 122, 0.9) 0%, rgba(138, 128, 117, 1) 100%);
            transform: translateY(-2px);
            box-shadow: 0 8px 25px rgba(156, 139, 122, 0.3);
        }
        
        .btn-ghost {
            background: transparent;
            color: var(--text-muted);
            border: 1px solid var(--accent-light);
        }
        
        .btn-ghost:hover:not(:disabled) {
            background: rgba(156, 139, 122, 0.1);
            color: var(--text-dark);
        }
        
        button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none !important;
        }
        
        /* VAD Toggle */
        .vad-toggle {
            display: flex;
            align-items: center;
            gap: 14px;
            padding: 16px 20px;
            background: rgba(255, 255, 255, 0.5);
            border-radius: 12px;
            margin-bottom: 20px;
        }
        
        .switch {
            position: relative;
            width: 52px;
            height: 28px;
            flex-shrink: 0;
        }
        
        .switch input {
            opacity: 0;
            width: 0;
            height: 0;
        }
        
        .slider {
            position: absolute;
            cursor: pointer;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: var(--cream-dark);
            transition: 0.4s;
            border-radius: 28px;
            border: 1px solid var(--accent-light);
        }
        
        .slider:before {
            position: absolute;
            content: "";
            height: 20px;
            width: 20px;
            left: 3px;
            bottom: 3px;
            background: white;
            transition: 0.4s;
            border-radius: 50%;
            box-shadow: 0 2px 5px rgba(0,0,0,0.15);
        }
        
        input:checked + .slider {
            background: linear-gradient(135deg, #81c784 0%, #66bb6a 100%);
            border-color: rgba(76, 175, 80, 0.3);
        }
        
        input:checked + .slider:before {
            transform: translateX(24px);
        }
        
        .vad-label {
            color: var(--text-dark);
            font-size: 0.95rem;
        }
        
        /* Status */
        .status {
            padding: 14px 20px;
            border-radius: 10px;
            text-align: center;
            margin-bottom: 20px;
            font-size: 0.95rem;
            transition: all 0.3s ease;
        }
        
        .status.success {
            background: rgba(76, 175, 80, 0.15);
            color: #4a7c4d;
            border: 1px solid rgba(76, 175, 80, 0.2);
        }
        
        .status.error {
            background: rgba(198, 40, 40, 0.1);
            color: #a03030;
            border: 1px solid rgba(198, 40, 40, 0.2);
        }
        
        .status.recording {
            background: rgba(198, 40, 40, 0.12);
            color: #a03030;
            border: 1px solid rgba(198, 40, 40, 0.2);
            animation: recordingPulse 1.5s infinite;
        }
        
        .status.listening, .status.speaking {
            background: rgba(76, 175, 80, 0.12);
            color: #4a7c4d;
            border: 1px solid rgba(76, 175, 80, 0.2);
        }
        
        .status.processing {
            background: rgba(156, 139, 122, 0.15);
            color: var(--warm-brown);
            border: 1px solid rgba(156, 139, 122, 0.2);
        }
        
        .status-icon {
            width: 16px;
            height: 16px;
            display: inline-block;
            vertical-align: middle;
            margin-right: 6px;
        }
        
        .status-icon.spin {
            animation: spin 1s linear infinite;
        }
        
        @keyframes spin {
            from { transform: rotate(0deg); }
            to { transform: rotate(360deg); }
        }
        
        @keyframes recordingPulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.7; }
        }
        
        /* Audio Preview */
        .audio-preview {
            margin-bottom: 20px;
        }
        
        .audio-preview audio {
            width: 100%;
            height: 45px;
            border-radius: 10px;
        }
        
        .audio-preview.hidden {
            display: none;
        }
        
        /* Result Display */
        .result {
            border-radius: 12px;
            padding: 20px;
            background: rgba(255, 255, 255, 0.6);
            border: 1px solid var(--glass-border);
            max-height: 300px;
            overflow-y: auto;
        }
        
        .result.hidden {
            display: none;
        }
        
        .result-content {
            font-size: 0.95rem;
            line-height: 1.7;
            color: var(--text-dark);
        }
        
        .result-content strong {
            color: var(--warm-brown);
            font-weight: 600;
        }
        
        /* Scrollbar styling */
        ::-webkit-scrollbar {
            width: 6px;
        }
        
        ::-webkit-scrollbar-track {
            background: var(--cream-dark);
            border-radius: 3px;
        }
        
        ::-webkit-scrollbar-thumb {
            background: var(--accent-light);
            border-radius: 3px;
        }
        
        ::-webkit-scrollbar-thumb:hover {
            background: var(--accent);
        }
        
        /* Responsive */
        @media (max-width: 1024px) {
            .main-container {
                flex-direction: column;
            }
            
            .video-pane, .controls-pane {
                width: 100%;
            }
            
            .video-pane {
                height: 50vh;
                min-height: 300px;
            }
            
            .controls-pane {
                padding: 40px 30px;
            }
            
            h1 {
                font-size: 2.5rem;
            }
        }
        
        /* Theme Toggle Button */
        .theme-toggle {
            position: fixed;
            top: 20px;
            right: 20px;
            z-index: 1000;
            background: var(--glass-bg);
            border: 1px solid var(--glass-border);
            border-radius: 50%;
            width: 48px;
            height: 48px;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 24px;
            transition: all 0.3s ease;
            backdrop-filter: blur(10px);
            -webkit-backdrop-filter: blur(10px);
            box-shadow: 0 4px 15px var(--shadow-soft);
        }
        
        .theme-toggle:hover {
            transform: scale(1.1);
            box-shadow: 0 6px 25px var(--shadow-soft);
        }
        
        .theme-toggle .sun { display: block; }
        .theme-toggle .moon { display: none; }
        
        [data-theme="night"] .theme-toggle .sun { display: none; }
        [data-theme="night"] .theme-toggle .moon { display: block; }
        
        /* Settings Toggle Button */
        .settings-toggle {
            position: fixed;
            top: 78px;
            right: 20px;
            z-index: 1000;
            background: var(--glass-bg);
            border: 1px solid var(--glass-border);
            border-radius: 50%;
            width: 48px;
            height: 48px;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            transition: all 0.3s ease;
            backdrop-filter: blur(10px);
            -webkit-backdrop-filter: blur(10px);
            box-shadow: 0 4px 15px var(--shadow-soft);
            color: var(--text-dark);
        }
        
        .settings-toggle .settings-icon {
            font-size: 22px;
            line-height: 1;
            transition: transform 0.3s ease;
            display: block;
        }
        
        .settings-toggle:hover {
            transform: scale(1.1);
            box-shadow: 0 6px 25px var(--shadow-soft);
        }
        
        .settings-toggle.active .settings-icon {
            transform: rotate(90deg);
        }
        
        /* Settings Panel */
        .settings-panel {
            position: fixed;
            top: 0;
            right: -420px;
            width: 400px;
            height: 100vh;
            background: var(--glass-bg);
            backdrop-filter: blur(20px);
            -webkit-backdrop-filter: blur(20px);
            border-left: 1px solid var(--glass-border);
            box-shadow: -10px 0 40px var(--shadow-soft);
            z-index: 1010;  /* Higher than theme-toggle (1000) */
            padding: 80px 25px 40px;
            transition: right 0.4s cubic-bezier(0.4, 0, 0.2, 1);
            overflow-y: auto;
            overflow-x: hidden;
        }
        
        .settings-panel.open {
            right: 0;
        }
        
        .settings-panel h3 {
            font-family: 'Cormorant Garabald', serif;
            font-size: 1.5rem;
            font-weight: 400;
            color: var(--text-dark);
            margin-bottom: 20px;
            padding-bottom: 12px;
            border-bottom: 1px solid var(--glass-border);
            flex-shrink: 0;
        }
        
        .settings-panel .voice-selector {
            margin-bottom: 15px;
            flex-shrink: 0;
        }
        
        .settings-panel .vad-toggle {
            margin-bottom: 15px;
            flex-shrink: 0;
        }
        
        /* Persona Section */
        .persona-section {
            margin-bottom: 20px;
            padding-bottom: 15px;
            border-bottom: 1px solid var(--glass-border);
        }
        
        .persona-selector {
            margin-bottom: 12px;
        }
        
        .persona-selector label {
            display: block;
            margin-bottom: 8px;
            color: var(--text-muted);
            font-size: 11px;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.1em;
        }
        
        .persona-controls {
            display: flex;
            gap: 8px;
            align-items: center;
        }
        
        .persona-controls select {
            flex: 1;
            padding: 10px 14px;
            border: 1px solid var(--accent-light);
            border-radius: 8px;
            background: rgba(255, 255, 255, 0.6);
            font-family: 'Raleway', sans-serif;
            font-size: 14px;
            color: var(--text-dark);
            cursor: pointer;
        }
        
        .persona-controls select:hover {
            border-color: var(--accent);
        }
        
        .persona-controls .icon-btn {
            width: 36px;
            height: 36px;
            padding: 0;
            display: flex;
            align-items: center;
            justify-content: center;
            border: 1px solid var(--accent-light);
            border-radius: 8px;
            background: rgba(255, 255, 255, 0.5);
            color: var(--text-muted);
            cursor: pointer;
            transition: all 0.2s ease;
        }
        
        .persona-controls .icon-btn:hover {
            border-color: var(--accent);
            background: rgba(255, 255, 255, 0.8);
            color: var(--text-dark);
        }
        
        .prompt-details {
            margin-top: 12px;
        }
        
        .prompt-details summary {
            cursor: pointer;
            font-size: 12px;
            color: var(--text-muted);
            padding: 8px 0;
            user-select: none;
        }
        
        .prompt-details summary:hover {
            color: var(--text-dark);
        }
        
        .prompt-details[open] summary {
            margin-bottom: 8px;
        }
        
        #personaPrompt {
            width: 100%;
            padding: 12px;
            border: 1px solid var(--accent-light);
            border-radius: 8px;
            background: rgba(255, 255, 255, 0.6);
            font-family: 'Raleway', sans-serif;
            font-size: 13px;
            line-height: 1.5;
            resize: vertical;
            min-height: 80px;
        }
        
        #personaPrompt:focus {
            outline: none;
            border-color: var(--warm-brown);
            box-shadow: 0 0 0 3px rgba(156, 139, 122, 0.2);
        }
        
        .tools-list {
            display: flex;
            flex-direction: column;
            gap: 8px;
            margin-bottom: 12px;
        }
        
        .tool-toggle {
            display: flex;
            align-items: center;
            gap: 10px;
            padding: 8px 12px;
            background: rgba(255, 255, 255, 0.5);
            border-radius: 8px;
            cursor: pointer;
            transition: background 0.2s;
        }
        
        .tool-toggle:hover {
            background: rgba(255, 255, 255, 0.8);
        }
        
        .tool-toggle input[type="checkbox"] {
            width: 18px;
            height: 18px;
            accent-color: var(--warm-brown);
        }
        
        .tool-info {
            display: flex;
            flex-direction: column;
            gap: 2px;
        }
        
        .tool-name {
            font-size: 13px;
            font-weight: 500;
            color: var(--text-dark);
        }
        
        .tool-desc {
            font-size: 11px;
            color: var(--text-muted);
        }
        
        [data-theme="night"] .tool-toggle {
            background: rgba(20, 20, 30, 0.6);
        }
        
        [data-theme="night"] .tool-toggle:hover {
            background: rgba(30, 30, 45, 0.8);
        }
        
        .btn-save-prompt {
            margin-top: 8px;
            padding: 8px 16px;
            background: var(--accent);
            color: white;
            border: none;
            border-radius: 6px;
            font-size: 12px;
            font-weight: 600;
            cursor: pointer;
            transition: background 0.2s ease;
        }
        
        .btn-save-prompt:hover {
            background: var(--warm-brown);
        }
        
        /* Night mode persona styles */
        [data-theme="night"] .persona-controls select {
            background: rgba(20, 20, 30, 0.9);
            border-color: var(--accent-light);
            color: var(--text-dark);
        }
        
        [data-theme="night"] .persona-controls .icon-btn {
            background: rgba(20, 20, 30, 0.8);
            border-color: var(--accent-light);
        }
        
        [data-theme="night"] #personaPrompt {
            background: rgba(20, 20, 30, 0.9);
            border-color: var(--accent-light);
            color: var(--text-dark);
        }
        
        .settings-panel .btn-ghost {
            width: 100%;
            flex-shrink: 0;
        }
        
        /* Chat Log Section */
        .panel-section {
            margin-top: 20px;
            flex-shrink: 0;
        }
        
        .panel-section-header {
            display: flex;
            align-items: center;
            justify-content: space-between;
            margin-bottom: 10px;
        }
        
        .panel-section-title {
            font-size: 0.85rem;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.08em;
            color: var(--text-muted);
        }
        
        .panel-section-actions {
            display: flex;
            gap: 8px;
        }
        
        .icon-btn {
            background: transparent;
            border: 1px solid var(--glass-border);
            border-radius: 8px;
            width: 32px;
            height: 32px;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            color: var(--text-muted);
            transition: all 0.2s ease;
            padding: 0;
        }
        
        .icon-btn:hover {
            background: var(--accent-light);
            color: var(--text-dark);
            border-color: var(--accent);
        }
        
        .icon-btn svg {
            width: 16px;
            height: 16px;
            stroke: currentColor;
        }
        
        /* Chat Log Container */
        .chat-log-container {
            flex: 1;
            min-height: 150px;
            max-height: 300px;
            overflow-y: auto;
            background: rgba(255, 255, 255, 0.4);
            border: 1px solid var(--glass-border);
            border-radius: 12px;
            padding: 15px;
            margin-bottom: 15px;
        }
        
        [data-theme="night"] .chat-log-container {
            background: rgba(10, 10, 20, 0.8);
        }
        
        .chat-log-container::-webkit-scrollbar {
            width: 6px;
        }
        
        .chat-log-container::-webkit-scrollbar-track {
            background: transparent;
        }
        
        .chat-log-container::-webkit-scrollbar-thumb {
            background: var(--accent-light);
            border-radius: 3px;
        }
        
        .chat-log-empty {
            color: var(--text-muted);
            font-style: italic;
            text-align: center;
            padding: 20px;
        }
        
        .chat-message {
            margin-bottom: 12px;
            padding-bottom: 12px;
            border-bottom: 1px solid var(--glass-border);
        }
        
        .chat-message:last-child {
            margin-bottom: 0;
            padding-bottom: 0;
            border-bottom: none;
        }
        
        .chat-message strong {
            color: var(--accent);
            font-weight: 600;
        }
        
        /* Audio Section */
        .audio-section {
            flex-shrink: 0;
        }
        
        .audio-player-container {
            display: flex;
            align-items: center;
            gap: 10px;
            background: rgba(255, 255, 255, 0.4);
            border: 1px solid var(--glass-border);
            border-radius: 12px;
            padding: 12px;
        }
        
        [data-theme="night"] .audio-player-container {
            background: rgba(10, 10, 20, 0.8);
        }
        
        .audio-player-container audio {
            flex: 1;
            height: 36px;
            border-radius: 8px;
        }
        
        .audio-player-container.hidden {
            display: none;
        }
        
        /* API Configuration Section */
        .api-config-section {
            margin-top: 20px;
            padding-top: 20px;
            border-top: 1px solid var(--glass-border);
        }
        
        .api-mode-toggle {
            display: flex;
            gap: 20px;
            margin-bottom: 20px;
        }
        
        .api-mode-option {
            display: flex;
            align-items: center;
            gap: 8px;
            cursor: pointer;
            font-size: 0.9rem;
            color: var(--text-dark);
        }
        
        .api-mode-option input[type="radio"] {
            width: 18px;
            height: 18px;
            accent-color: var(--accent);
        }
        
        .api-section-card {
            background: rgba(255, 255, 255, 0.3);
            border: 1px solid var(--glass-border);
            border-radius: 12px;
            padding: 15px;
            margin-bottom: 15px;
        }
        
        [data-theme="night"] .api-section-card {
            background: rgba(20, 20, 30, 0.6);
        }
        
        .api-section-title {
            font-size: 0.85rem;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.05em;
            color: var(--text-muted);
            margin-bottom: 12px;
            display: flex;
            align-items: center;
            justify-content: space-between;
        }
        
        .api-section-title .detected-model {
            font-weight: 400;
            font-size: 0.75rem;
            text-transform: none;
            background: var(--accent-light);
            padding: 2px 8px;
            border-radius: 10px;
            color: var(--text-dark);
        }
        
        .api-field {
            margin-bottom: 12px;
        }
        
        .api-field:last-child {
            margin-bottom: 0;
        }
        
        .api-field label {
            display: block;
            font-size: 0.8rem;
            color: var(--text-muted);
            margin-bottom: 5px;
        }
        
        .api-field input,
        .api-field select {
            width: 100%;
            padding: 10px 12px;
            border: 1px solid var(--accent-light);
            border-radius: 8px;
            font-size: 0.9rem;
            background: rgba(255, 255, 255, 0.6);
            color: var(--text-dark);
            font-family: 'Raleway', sans-serif;
        }
        
        [data-theme="night"] .api-field input,
        [data-theme="night"] .api-field select {
            background: rgba(20, 20, 30, 0.8);
            border-color: var(--accent-light);
        }
        
        .api-field input:focus,
        .api-field select:focus {
            outline: none;
            border-color: var(--accent);
            box-shadow: 0 0 0 2px rgba(156, 139, 122, 0.2);
        }
        
        .api-field input[type="password"] {
            font-family: monospace;
            letter-spacing: 2px;
        }
        
        .api-field-row {
            display: flex;
            gap: 10px;
        }
        
        .api-field-row .api-field {
            flex: 1;
        }
        
        .test-btn {
            background: transparent;
            border: 1px solid var(--accent-light);
            border-radius: 8px;
            padding: 8px 12px;
            font-size: 0.8rem;
            cursor: pointer;
            color: var(--text-muted);
            transition: all 0.2s ease;
            white-space: nowrap;
        }
        
        .test-btn:hover {
            background: var(--accent-light);
            color: var(--text-dark);
        }
        
        .test-btn.success {
            background: rgba(76, 175, 80, 0.2);
            border-color: rgba(76, 175, 80, 0.5);
            color: #4a7c4d;
        }
        
        .test-btn.error {
            background: rgba(198, 40, 40, 0.2);
            border-color: rgba(198, 40, 40, 0.5);
            color: #c62828;
        }
        
        .save-config-btn {
            width: 100%;
            padding: 12px;
            background: linear-gradient(135deg, var(--accent) 0%, var(--warm-brown) 100%);
            border: none;
            border-radius: 10px;
            color: white;
            font-size: 0.95rem;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.3s ease;
            margin-top: 15px;
        }
        
        .save-config-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(156, 139, 122, 0.3);
        }
        
        .config-status {
            text-align: center;
            font-size: 0.85rem;
            margin-top: 10px;
            padding: 8px;
            border-radius: 8px;
        }
        
        .config-status.success {
            background: rgba(76, 175, 80, 0.15);
            color: #4a7c4d;
        }
        
        .config-status.error {
            background: rgba(198, 40, 40, 0.15);
            color: #c62828;
        }
        
        .hidden-section {
            display: none;
        }
        
        /* Overlay when settings open */
        .settings-overlay {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.3);
            z-index: 998;
            opacity: 0;
            visibility: hidden;
            transition: opacity 0.3s ease, visibility 0.3s ease;
        }
        
        .settings-overlay.visible {
            opacity: 1;
            visibility: visible;
        }
        
        /* Listen Toggle */
        .listen-toggle-container {
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 12px;
            margin: 30px 0;
        }
        
        .listen-label {
            font-size: 0.75rem;
            font-weight: 500;
            text-transform: uppercase;
            letter-spacing: 0.08em;
            color: var(--text-muted);
            transition: color 0.3s ease;
        }
        
        .listen-label.ignore.active,
        .listen-label.listen.active {
            color: var(--text-dark);
        }
        
        .listen-switch {
            position: relative;
            width: 50px;
            height: 26px;
        }
        
        .listen-switch input {
            opacity: 0;
            width: 0;
            height: 0;
        }
        
        .listen-slider {
            position: absolute;
            cursor: pointer;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: var(--cream-dark);
            transition: 0.4s cubic-bezier(0.4, 0, 0.2, 1);
            border-radius: 26px;
            border: 1px solid var(--accent-light);
        }
        
        .listen-slider:before {
            position: absolute;
            content: "";
            height: 20px;
            width: 20px;
            left: 2px;
            bottom: 2px;
            background: white;
            transition: 0.4s cubic-bezier(0.4, 0, 0.2, 1);
            border-radius: 50%;
            box-shadow: 0 2px 6px rgba(0,0,0,0.2);
        }
        
        .listen-switch input:checked + .listen-slider {
            background: linear-gradient(135deg, #81c784 0%, #66bb6a 100%);
            border-color: rgba(76, 175, 80, 0.3);
        }
        
        .listen-switch input:checked + .listen-slider:before {
            transform: translateX(24px);
        }
        
        .listen-switch input:disabled + .listen-slider {
            opacity: 0.5;
            cursor: not-allowed;
        }
        
        /* Dynamic tagline styles */
        .subtitle {
            transition: all 0.3s ease;
        }
        
        .subtitle.listening {
            color: #4a7c4d;
        }
        
        .subtitle.active {
            color: #4a7c4d;
            font-weight: 400;
        }
        
        /* Lucide Icon Styling */
        .lucide {
            width: 1em;
            height: 1em;
            stroke-width: 2;
            vertical-align: middle;
        }
        
        .theme-toggle .lucide {
            width: 24px;
            height: 24px;
            stroke: var(--text-dark);
        }
        
        
        .btn-row .lucide {
            width: 18px;
            height: 18px;
            margin-right: 6px;
        }
        
        @keyframes spin {
            from { transform: rotate(0deg); }
            to { transform: rotate(360deg); }
        }
    </style>
</head>
<body>
    <!-- Theme Toggle -->
    <button class="theme-toggle" onclick="toggleTheme()" aria-label="Toggle theme">
        <span class="sun"><i data-lucide="sun"></i></span>
        <span class="moon"><i data-lucide="moon"></i></span>
    </button>
    
    <!-- Settings Toggle -->
    <button class="settings-toggle" onclick="toggleSettings()" aria-label="Toggle settings">
        <span class="settings-icon">‚öô</span>
    </button>
    
    <!-- Settings Overlay -->
    <div class="settings-overlay" onclick="toggleSettings()"></div>
    
    <!-- Settings Panel -->
    <div class="settings-panel" id="settingsPanel">
        <h3>Settings</h3>
        
        <!-- Persona Selector -->
        <div class="persona-section">
            <div class="persona-selector">
                <label for="personaSelect">Persona</label>
                <div class="persona-controls">
                    <select id="personaSelect">
                        <option value="default">Groklexa</option>
                    </select>
                    <button class="icon-btn persona-edit-btn" id="personaEditBtn" title="Edit persona">
                        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M17 3a2.85 2.83 0 1 1 4 4L7.5 20.5 2 22l1.5-5.5Z"/><path d="m15 5 4 4"/></svg>
                    </button>
                    <button class="icon-btn persona-add-btn" id="personaAddBtn" title="Create new persona">
                        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M5 12h14"/><path d="M12 5v14"/></svg>
                    </button>
                </div>
            </div>
            
            <!-- Prompt Textarea (collapsible) -->
            <details class="prompt-details">
                <summary>System Prompt</summary>
                <textarea id="personaPrompt" rows="4" placeholder="Enter the system prompt for this persona..."></textarea>
                <button class="btn-save-prompt" id="savePromptBtn">Save Prompt</button>
            </details>
            
            <!-- Tool Permissions (collapsible) -->
            <details class="prompt-details tools-details">
                <summary>Tool Permissions</summary>
                <div class="tools-list">
                    <label class="tool-toggle">
                        <input type="checkbox" id="toolDateTime" checked>
                        <span class="tool-info">
                            <span class="tool-name">üìÖ Date & Time</span>
                            <span class="tool-desc">Get current date/time (local)</span>
                        </span>
                    </label>
                    <label class="tool-toggle">
                        <input type="checkbox" id="toolWeather" checked>
                        <span class="tool-info">
                            <span class="tool-name">üå§Ô∏è Weather</span>
                            <span class="tool-desc">Current weather (requires OpenWeatherMap API)</span>
                        </span>
                    </label>
                    <label class="tool-toggle">
                        <input type="checkbox" id="toolTimer" checked>
                        <span class="tool-info">
                            <span class="tool-name">‚è±Ô∏è Timers</span>
                            <span class="tool-desc">Set and list timers/reminders (local)</span>
                        </span>
                    </label>
                    <label class="tool-toggle">
                        <input type="checkbox" id="toolSystemInfo" checked>
                        <span class="tool-info">
                            <span class="tool-name">üñ•Ô∏è System Info</span>
                            <span class="tool-desc">CPU, memory, disk, GPU usage (local)</span>
                        </span>
                    </label>
                    <label class="tool-toggle">
                        <input type="checkbox" id="toolEscalate" checked>
                        <span class="tool-info">
                            <span class="tool-name">üß† Deep Thinking</span>
                            <span class="tool-desc">Escalate to cloud model for complex reasoning</span>
                        </span>
                    </label>
                    <label class="tool-toggle">
                        <input type="checkbox" id="toolSearchX" checked>
                        <span class="tool-info">
                            <span class="tool-name">üê¶ Search X</span>
                            <span class="tool-desc">Search posts on X (requires xAI API)</span>
                        </span>
                    </label>
                    <label class="tool-toggle">
                        <input type="checkbox" id="toolSearchWeb" checked>
                        <span class="tool-info">
                            <span class="tool-name">üåê Search Web</span>
                            <span class="tool-desc">Web search (requires xAI API)</span>
                        </span>
                    </label>
                </div>
                <button class="btn-save-prompt" id="saveToolsBtn">Save Tools</button>
            </details>
        </div>
        
        <div class="vad-toggle">
            <label class="switch">
                <input type="checkbox" id="vadToggle">
                <span class="slider"></span>
            </label>
            <span class="vad-label">Manual VAD (volume-based)</span>
        </div>
        
        <div class="vad-toggle">
            <label class="switch">
                <input type="checkbox" id="earconsToggle" checked>
                <span class="slider"></span>
            </label>
            <span class="vad-label">üîî Earcons (UI sounds)</span>
        </div>
        
        <div class="vad-toggle">
            <label class="switch">
                <input type="checkbox" id="fillersToggle" checked>
                <span class="slider"></span>
            </label>
            <span class="vad-label">üó£Ô∏è Verbal fillers (umm, hmm...)</span>
        </div>
        
        <!-- API Configuration Section -->
        <div class="api-config-section">
            <div class="panel-section-header">
                <span class="panel-section-title">API Configuration</span>
            </div>
            
            <!-- Mode Toggle -->
            <div class="api-mode-toggle">
                <label class="api-mode-option">
                    <input type="radio" name="apiMode" value="single" id="apiModeSingle" checked>
                    <span>Single API</span>
                </label>
                <label class="api-mode-option">
                    <input type="radio" name="apiMode" value="separate" id="apiModeSeparate">
                    <span>Separate APIs</span>
                </label>
            </div>
            
            <!-- Single API Config -->
            <div id="singleApiConfig">
                <div class="api-section-card">
                    <div class="api-section-title">
                        <span>Unified API</span>
                        <span class="detected-model" id="singleDetectedModel" style="display:none;"></span>
                    </div>
                    <div class="api-field">
                        <label>Provider</label>
                        <select id="singleProvider">
                            <option value="xai_realtime">XAI Realtime (WebSocket)</option>
                            <option value="custom">Custom URL</option>
                        </select>
                    </div>
                    <div class="api-field">
                        <label>URL</label>
                        <input type="text" id="singleUrl" placeholder="wss://api.x.ai/v1/realtime">
                    </div>
                    <div class="api-field-row">
                        <div class="api-field">
                            <label>Auth Key</label>
                            <input type="password" id="singleAuth" placeholder="API key or token">
                        </div>
                        <button class="test-btn" onclick="testConnection('single')">Test</button>
                    </div>
                    <div class="api-field">
                        <label>Voice</label>
                        <select id="singleVoice">
                            <option value="Ara">Ara (default)</option>
                            <option value="Rex">Rex</option>
                            <option value="Sal">Sal</option>
                            <option value="Eve">Eve</option>
                            <option value="Leo">Leo</option>
                        </select>
                    </div>
                </div>
            </div>
            
            <!-- Separate APIs Config -->
            <div id="separateApiConfig" class="hidden-section">
                <!-- Transcription -->
                <div class="api-section-card">
                    <div class="api-section-title">
                        <span>Transcription</span>
                        <span class="detected-model" id="transcriptionDetectedModel" style="display:none;"></span>
                    </div>
                    <div class="api-field">
                        <label>Provider</label>
                        <select id="transcriptionProvider">
                            <option value="browser">Browser (Web Speech API)</option>
                            <option value="local_whisper">Local Whisper (Free, Offline)</option>
                            <option value="grok">Grok API</option>
                            <option value="whisper">OpenAI Whisper</option>
                            <option value="google">Google Cloud Speech</option>
                            <option value="custom">Custom URL</option>
                        </select>
                    </div>
                    <div class="api-field whisper-model-field" style="display:none;">
                        <label>Model Size</label>
                        <select id="whisperModelSize">
                            <option value="tiny">Tiny (fastest, least accurate)</option>
                            <option value="base" selected>Base (balanced)</option>
                            <option value="small">Small (better accuracy)</option>
                            <option value="medium">Medium (high accuracy)</option>
                            <option value="large-v3">Large V3 (best, slowest)</option>
                        </select>
                        <button class="test-btn" id="loadWhisperBtn" onclick="loadWhisperModel()">Load Model</button>
                    </div>
                    <div class="api-field transcription-url-field">
                        <label>URL</label>
                        <input type="text" id="transcriptionUrl" placeholder="API endpoint URL">
                    </div>
                    <div class="api-field-row" id="transcriptionAuthField">
                        <div class="api-field">
                            <label>Auth Key</label>
                            <input type="password" id="transcriptionAuth" placeholder="API key">
                        </div>
                        <button class="test-btn" onclick="testConnection('transcription')">Test</button>
                    </div>
                </div>
                
                <!-- Inference -->
                <div class="api-section-card">
                    <div class="api-section-title">
                        <span>Inference (LLM)</span>
                        <span class="detected-model" id="inferenceDetectedModel" style="display:none;"></span>
                    </div>
                    <div class="api-field">
                        <label>Provider</label>
                        <select id="inferenceProvider">
                            <option value="grok">Grok API</option>
                            <option value="anthropic">Anthropic (Claude)</option>
                            <option value="openai">OpenAI</option>
                            <option value="ollama">Local (Ollama)</option>
                            <option value="llama_cpp">Local (llama.cpp)</option>
                            <option value="custom">Custom URL</option>
                        </select>
                    </div>
                    <div class="api-field">
                        <label>Model</label>
                        <select id="inferenceModel">
                            <option value="">Loading models...</option>
                        </select>
                    </div>
                    <div class="api-field inference-url-field">
                        <label>URL</label>
                        <input type="text" id="inferenceUrl" placeholder="API endpoint URL">
                    </div>
                    <div class="api-field-row inference-auth-field">
                        <div class="api-field">
                            <label>Auth Key</label>
                            <input type="password" id="inferenceAuth" placeholder="API key">
                        </div>
                        <button class="test-btn" onclick="testConnection('inference')">Test</button>
                    </div>
                </div>
                
                <!-- Synthesis -->
                <div class="api-section-card">
                    <div class="api-section-title">
                        <span>Synthesis (TTS)</span>
                        <span class="detected-model" id="synthesisDetectedModel" style="display:none;"></span>
                    </div>
                    <div class="api-field">
                        <label>Provider</label>
                        <select id="synthesisProvider">
                            <option value="browser">Browser (Web Speech API)</option>
                            <option value="chatterbox">Chatterbox (Local GPU)</option>
                            <option value="edge_tts">Edge TTS (Free, Local)</option>
                            <option value="grok">Grok API</option>
                            <option value="openai_tts">OpenAI TTS</option>
                            <option value="elevenlabs">ElevenLabs</option>
                            <option value="custom">Custom URL</option>
                        </select>
                    </div>
                    <div class="api-field">
                        <label>Voice</label>
                        <select id="synthesisVoice">
                            <option value="">Select a voice...</option>
                        </select>
                    </div>
                    <div class="api-field synthesis-url-field">
                        <label>URL</label>
                        <input type="text" id="synthesisUrl" placeholder="API endpoint URL">
                    </div>
                    <div class="api-field-row synthesis-auth-field">
                        <div class="api-field">
                            <label>Auth Key</label>
                            <input type="password" id="synthesisAuth" placeholder="API key">
                        </div>
                        <button class="test-btn" onclick="testConnection('synthesis')">Test</button>
                    </div>
                </div>
            </div>
            
            <button class="save-config-btn" onclick="saveApiConfig()">Save Configuration</button>
            <div id="configStatus" class="config-status" style="display:none;"></div>
        </div>
        
        <!-- Chat Log Section -->
        <div class="panel-section">
            <div class="panel-section-header">
                <span class="panel-section-title">Conversation</span>
                <div class="panel-section-actions">
                    <button class="icon-btn" id="copyLogBtn" title="Copy conversation">
                        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"/><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"/></svg>
                    </button>
                    <button class="icon-btn" id="clearHistoryBtn" title="Clear conversation">
                        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M3 6h18"/><path d="M19 6v14c0 1-1 2-2 2H7c-1 0-2-1-2-2V6"/><path d="M8 6V4c0-1 1-2 2-2h4c1 0 2 1 2 2v2"/></svg>
                    </button>
                </div>
            </div>
            <div class="chat-log-container" id="chatLogContainer">
                <div class="chat-log-empty" id="chatLogEmpty">No conversation yet</div>
                <div id="resultContent" class="result-content"></div>
            </div>
        </div>
        
        <!-- Audio Section -->
        <div class="panel-section audio-section">
            <div class="panel-section-header">
                <span class="panel-section-title">Last Response Audio</span>
                <div class="panel-section-actions">
                    <button class="icon-btn" id="downloadAudioBtn" title="Download audio">
                        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 15v4a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2v-4"/><polyline points="7 10 12 15 17 10"/><line x1="12" x2="12" y1="15" y2="3"/></svg>
                    </button>
                </div>
            </div>
            <div class="audio-player-container hidden" id="audioPlayerContainer">
                <audio id="aiAudioPlayer" controls></audio>
            </div>
            <div class="audio-player-container hidden" id="audioPreview">
                <audio id="audioPlayer" controls></audio>
            </div>
        </div>
    </div>
    
    <div class="main-container">
        <!-- Left Pane - Video -->
        <div class="video-pane">
            <div class="video-container">
                <video id="groklexaVideo" muted playsinline>
                    <source src="/static/videos/groklexa.mp4" type="video/mp4">
                </video>
            </div>
        </div>
        
        <!-- Right Pane - Controls -->
        <div class="controls-pane">
            <div class="controls-inner">
                <h1>Groklexa</h1>
                <p class="subtitle" id="tagline">Configurable AI voice wrapper</p>
                
                <!-- Listen Toggle -->
                <div class="listen-toggle-container">
                    <span class="listen-label ignore">Ignore</span>
                    <label class="listen-switch">
                        <input type="checkbox" id="listenToggle">
                        <span class="listen-slider"></span>
                    </label>
                    <span class="listen-label listen">Listen</span>
                </div>
                
                <!-- Status (for errors only) -->
                <div id="status" class="status hidden"></div>
            </div>
        </div>
    </div>

    <script>
        // ========== THEME TOGGLE ==========
        const DAY_VIDEO = '/static/videos/groklexa.mp4';
        const NIGHT_VIDEO = '/static/videos/groklexa-night-mode.mp4';
        
        function getPreferredTheme() {
            const stored = localStorage.getItem('groklexa-theme');
            if (stored) return stored;
            // Check system preference
            if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
                return 'night';
            }
            return 'day';
        }
        
        function setTheme(theme) {
            document.documentElement.setAttribute('data-theme', theme);
            localStorage.setItem('groklexa-theme', theme);
            
            // Switch video source
            const video = document.getElementById('groklexaVideo');
            if (video) {
                const currentTime = video.currentTime;
                video.src = theme === 'night' ? NIGHT_VIDEO : DAY_VIDEO;
                video.load();
                // Restore position if video was playing
                video.currentTime = Math.min(currentTime, video.duration || 0);
            }
            
            console.log('Theme set to:', theme);
        }
        
        function toggleTheme() {
            const current = document.documentElement.getAttribute('data-theme') || 'day';
            const newTheme = current === 'night' ? 'day' : 'night';
            setTheme(newTheme);
        }
        
        // ========== SETTINGS PANEL ==========
        function toggleSettings() {
            const panel = document.getElementById('settingsPanel');
            const overlay = document.querySelector('.settings-overlay');
            const toggle = document.querySelector('.settings-toggle');
            
            panel.classList.toggle('open');
            overlay.classList.toggle('visible');
            toggle.classList.toggle('active');
        }
        
        // Initialize theme on page load
        document.addEventListener('DOMContentLoaded', () => {
            setTheme(getPreferredTheme());
            // Initialize Lucide icons (with retry for async loading)
            function initLucide() {
                if (typeof lucide !== 'undefined' && lucide.createIcons) {
                    lucide.createIcons();
                } else {
                    setTimeout(initLucide, 100);
                }
            }
            initLucide();
        });
        
        // ========== MAIN APP ==========
        let mediaRecorder;
        let audioChunks = [];
        let audioBlob;
        let conversationHistory = [];
        let vad = null;
        let isVadActive = false;
        let isProcessing = false;
        let isAISpeaking = false;  // Prevent VAD from hearing AI's speech
        let currentAbortController = null;
        
        // Audio feedback settings
        let earconsEnabled = localStorage.getItem('earconsEnabled') !== 'false';
        let fillersEnabled = localStorage.getItem('fillersEnabled') !== 'false';
        let wakeWordAborted = false;

        // ========== WAKE WORD DETECTION (OpenWakeWord) ==========
        let wakeWordState = 'loading';
        let wakeWordModels = {
            melspec: null,
            embedding: null,
            vad: null,
            wakeword: null
        };
        let wakeWordAudioContext = null;
        let wakeWordWorkletNode = null;
        let wakeWordStream = null;
        let wakeWordSuccessSound = null;

        // Wake word buffers
        let ww_mel_buffer = [];
        let ww_embedding_buffer = [];
        let ww_vadState = { h: null, c: null };
        let ww_isSpeechActive = false;
        let ww_vadHangoverCounter = 0;
        const WW_VAD_HANGOVER_FRAMES = 12;
        const WW_SAMPLE_RATE = 16000;
        const WW_FRAME_SIZE = 1280;
        let ww_isDetectionCoolingDown = false;
        
        // Silero VAD-based recording (uses neural network for speech detection)
        let sileroRecorder = null;
        let sileroAudioChunks = [];
        let sileroWasSpeaking = false;  // Track speech state changes
        let sileroSpeechStartTime = null;
        const SILERO_MIN_SPEECH_DURATION = 500;  // Minimum speech duration in ms
        
        // Note: Pre-buffer removed - continuous recording now captures everything
        // WebM format requires sequential chunks, so we keep all chunks from session start

        // Video element
        const groklexaVideo = document.getElementById('groklexaVideo');
        let videoPlaybackRate = 1;

        const status = document.getElementById('status');
        const audioPreview = document.getElementById('audioPreview');
        const audioPlayer = document.getElementById('audioPlayer');
        const audioPlayerContainer = document.getElementById('audioPlayerContainer');
        const aiAudioPlayer = document.getElementById('aiAudioPlayer');
        const resultContent = document.getElementById('resultContent');
        const chatLogContainer = document.getElementById('chatLogContainer');
        const chatLogEmpty = document.getElementById('chatLogEmpty');
        const vadToggle = document.getElementById('vadToggle');
        const copyLogBtn = document.getElementById('copyLogBtn');
        const downloadAudioBtn = document.getElementById('downloadAudioBtn');
        const settingsPanel = document.getElementById('settingsPanel');
        
        let lastAudioBlob = null;  // Store last audio for download

        // ========== VIDEO CONTROL ==========
        
        function playVideoForward() {
            groklexaVideo.playbackRate = 1;
            groklexaVideo.play();
        }
        
        function playVideoBackward() {
            // For reverse playback, we'll use a frame-by-frame approach
            const video = groklexaVideo;
            const frameRate = 30; // Assume 30fps
            const frameTime = 1 / frameRate;
            
            function stepBack() {
                if (video.currentTime <= 0) {
                    video.currentTime = 0;
                    return;
                }
                video.currentTime = Math.max(0, video.currentTime - frameTime);
                requestAnimationFrame(stepBack);
            }
            
            video.pause();
            stepBack();
        }

        // ========== HELPER FUNCTIONS ==========
        
        function showStatus(message, type = 'info') {
            // Support Lucide icons in status messages
            // Replace emoji patterns with Lucide icons
            const iconMap = {
                'ü§î': '<i data-lucide="brain" class="status-icon"></i>',
                'üé§': '<i data-lucide="mic" class="status-icon"></i>',
                'üéß': '<i data-lucide="headphones" class="status-icon"></i>',
                'üîä': '<i data-lucide="volume-2" class="status-icon"></i>',
                '‚è≥': '<i data-lucide="loader-2" class="status-icon spin"></i>',
                '‚úÖ': '<i data-lucide="check-circle" class="status-icon"></i>',
                'üß†': '<i data-lucide="sparkles" class="status-icon"></i>',
                'üîß': '<i data-lucide="wrench" class="status-icon"></i>',
            };
            
            let processedMessage = message;
            for (const [emoji, icon] of Object.entries(iconMap)) {
                processedMessage = processedMessage.replace(emoji, icon);
            }
            
            status.innerHTML = processedMessage;
            status.className = 'status ' + type;
            status.classList.remove('hidden');
            
            // Re-render Lucide icons
            if (typeof lucide !== 'undefined') {
                lucide.createIcons();
            }
        }

        function hideStatus() {
            status.classList.add('hidden');
        }
        
        // ========== EARCON SYSTEM (Audio cues) ==========
        
        // Pre-generated earcon sounds using Web Audio API
        const earconContext = new (window.AudioContext || window.webkitAudioContext)();
        
        function playEarcon(type) {
            // Resume context if suspended (browser autoplay policy)
            if (earconContext.state === 'suspended') {
                earconContext.resume();
            }
            
            const oscillator = earconContext.createOscillator();
            const gainNode = earconContext.createGain();
            oscillator.connect(gainNode);
            gainNode.connect(earconContext.destination);
            
            const now = earconContext.currentTime;
            
            switch(type) {
                case 'ding':
                    // Single pleasant ding - for greetings/acknowledgment
                    oscillator.type = 'sine';
                    oscillator.frequency.setValueAtTime(880, now);
                    gainNode.gain.setValueAtTime(0.2, now);
                    gainNode.gain.exponentialRampToValueAtTime(0.01, now + 0.3);
                    oscillator.start(now);
                    oscillator.stop(now + 0.3);
                    break;
                    
                case 'blip':
                    // Short blip - for uncertain/novel states
                    oscillator.type = 'sine';
                    oscillator.frequency.setValueAtTime(440, now);
                    oscillator.frequency.exponentialRampToValueAtTime(660, now + 0.1);
                    gainNode.gain.setValueAtTime(0.15, now);
                    gainNode.gain.exponentialRampToValueAtTime(0.01, now + 0.15);
                    oscillator.start(now);
                    oscillator.stop(now + 0.15);
                    break;
                    
                case 'boop_boop':
                    // Double boop - for tool intent
                    oscillator.type = 'sine';
                    oscillator.frequency.setValueAtTime(523, now);
                    gainNode.gain.setValueAtTime(0.15, now);
                    gainNode.gain.exponentialRampToValueAtTime(0.01, now + 0.1);
                    // Second boop
                    setTimeout(() => {
                        const osc2 = earconContext.createOscillator();
                        const gain2 = earconContext.createGain();
                        osc2.connect(gain2);
                        gain2.connect(earconContext.destination);
                        osc2.type = 'sine';
                        osc2.frequency.setValueAtTime(659, earconContext.currentTime);
                        gain2.gain.setValueAtTime(0.15, earconContext.currentTime);
                        gain2.gain.exponentialRampToValueAtTime(0.01, earconContext.currentTime + 0.1);
                        osc2.start(earconContext.currentTime);
                        osc2.stop(earconContext.currentTime + 0.1);
                    }, 120);
                    oscillator.start(now);
                    oscillator.stop(now + 0.1);
                    break;
                    
                case 'whirr':
                    // Soft whirr - for task-focused/heavy thinking
                    oscillator.type = 'triangle';
                    oscillator.frequency.setValueAtTime(220, now);
                    oscillator.frequency.linearRampToValueAtTime(330, now + 0.2);
                    oscillator.frequency.linearRampToValueAtTime(220, now + 0.4);
                    gainNode.gain.setValueAtTime(0.1, now);
                    gainNode.gain.exponentialRampToValueAtTime(0.01, now + 0.5);
                    oscillator.start(now);
                    oscillator.stop(now + 0.5);
                    break;
                    
                case 'processing':
                    // Brief processing tone - for professional contexts
                    oscillator.type = 'sine';
                    oscillator.frequency.setValueAtTime(392, now);
                    oscillator.frequency.exponentialRampToValueAtTime(494, now + 0.15);
                    gainNode.gain.setValueAtTime(0.12, now);
                    gainNode.gain.exponentialRampToValueAtTime(0.01, now + 0.2);
                    oscillator.start(now);
                    oscillator.stop(now + 0.2);
                    break;
                    
                default:
                    // Default soft tone
                    oscillator.type = 'sine';
                    oscillator.frequency.setValueAtTime(440, now);
                    gainNode.gain.setValueAtTime(0.1, now);
                    gainNode.gain.exponentialRampToValueAtTime(0.01, now + 0.2);
                    oscillator.start(now);
                    oscillator.stop(now + 0.2);
            }
            
            console.log(`[Groklexa] Played earcon: ${type}`);
        }
        
        // ========== FILE-BASED EARCONS & FILLERS ==========
        
        // Cache of loaded earcon/filler audio buffers
        const earconCache = {};
        const fillerCache = {};
        let currentTiming = { transcription_ms: 500, inference_ms: 2000, synthesis_ms: 1500, total_ms: 4000 };
        
        // Preload stock earcons
        async function preloadEarcons() {
            const earconFiles = ['ding', 'thinking', 'active', 'speaking', 'tool_calling', 'error', 'waiting'];
            
            for (const name of earconFiles) {
                try {
                    const response = await fetch(`/static/earcons/${name}.wav`);
                    if (response.ok) {
                        const arrayBuffer = await response.arrayBuffer();
                        earconCache[name] = await earconContext.decodeAudioData(arrayBuffer);
                        console.log(`[Groklexa] Preloaded earcon: ${name}`);
                    }
                } catch (e) {
                    console.warn(`[Groklexa] Could not preload earcon ${name}:`, e);
                }
            }
        }
        
        // Play a file-based earcon
        function playFileEarcon(name) {
            if (!earconsEnabled) {
                console.log(`[Groklexa] Earcons disabled, skipping: ${name}`);
                return;
            }
            
            if (earconContext.state === 'suspended') {
                earconContext.resume();
            }
            
            const buffer = earconCache[name];
            if (!buffer) {
                console.warn(`[Groklexa] Earcon not loaded: ${name}, using synthesized`);
                playEarcon(name);  // Fall back to synthesized
                return;
            }
            
            const source = earconContext.createBufferSource();
            source.buffer = buffer;
            
            const gainNode = earconContext.createGain();
            gainNode.gain.value = 0.3;  // Adjust volume
            
            source.connect(gainNode);
            gainNode.connect(earconContext.destination);
            source.start();
            
            console.log(`[Groklexa] Played file earcon: ${name}`);
        }
        
        // Load persona-specific fillers
        let loadedFillerPersonaId = null;
        
        async function loadPersonaFillers(personaId) {
            if (personaId === loadedFillerPersonaId && Object.keys(fillerCache).length > 0) {
                return;  // Already loaded
            }
            loadedFillerPersonaId = personaId;
            
            try {
                // First, try to load existing fillers
                const response = await fetch(`/api/fillers/${personaId}`);
                const data = await response.json();
                
                if (data.success) {
                    // Load persona-specific fillers
                    for (const filler of data.persona_fillers) {
                        try {
                            const audioResponse = await fetch(filler.path);
                            if (audioResponse.ok) {
                                const arrayBuffer = await audioResponse.arrayBuffer();
                                // Extract name (e.g., "umm" from "umm.wav", "one-moment" from "one-moment.wav")
                                const name = filler.filename.replace('.wav', '');
                                fillerCache[name] = await earconContext.decodeAudioData(arrayBuffer);
                                console.log(`[Groklexa] Loaded filler: ${name}`);
                            }
                        } catch (e) {
                            console.warn(`[Groklexa] Could not load filler ${filler.filename}:`, e);
                        }
                    }
                }
                
                // Pre-fetch all filler phrases if not already cached
                const essentialFillers = ['umm', 'hmm', 'let-me-think', 'one-moment', 'well'];
                for (const phrase of essentialFillers) {
                    if (!fillerCache[phrase]) {
                        // Don't await - let them generate in parallel
                        fetchOrGenerateFiller(personaId, phrase).catch(e => 
                            console.warn(`[Groklexa] Could not pre-fetch filler ${phrase}:`, e)
                        );
                    }
                }
                
            } catch (e) {
                console.warn('[Groklexa] Could not load persona fillers:', e);
            }
        }
        
        // Fetch a filler, generating it on-demand if needed
        async function fetchOrGenerateFiller(personaId, phrase) {
            try {
                console.log(`[Groklexa] Fetching/generating filler: ${phrase}`);
                const response = await fetch(`/api/fillers/${personaId}/get/${phrase}`);
                
                if (response.ok) {
                    const arrayBuffer = await response.arrayBuffer();
                    fillerCache[phrase] = await earconContext.decodeAudioData(arrayBuffer);
                    console.log(`[Groklexa] Loaded filler: ${phrase}`);
                    return true;
                }
            } catch (e) {
                console.warn(`[Groklexa] Could not fetch filler ${phrase}:`, e);
            }
            return false;
        }
        
        // Play a persona-voiced filler
        function playPersonaFiller(phrase) {
            if (!fillersEnabled) {
                console.log(`[Groklexa] Fillers disabled, skipping: ${phrase}`);
                return;
            }
            
            if (earconContext.state === 'suspended') {
                earconContext.resume();
            }
            
            const buffer = fillerCache[phrase];
            if (!buffer) {
                console.warn(`[Groklexa] Filler not loaded: ${phrase}, using stock earcon`);
                playFileEarcon('thinking');
                return;
            }
            
            const source = earconContext.createBufferSource();
            source.buffer = buffer;
            
            const gainNode = earconContext.createGain();
            gainNode.gain.value = 0.5;  // Slightly louder for voice fillers
            
            source.connect(gainNode);
            gainNode.connect(earconContext.destination);
            source.start();
            
            console.log(`[Groklexa] Played persona filler: ${phrase}`);
        }
        
        // Filler rotation state
        let lastFillerIndex = -1;
        let fillerChainActive = false;
        let fillerChainAbort = false;
        
        // Short fillers for quick responses, longer ones for extended waits
        const shortFillers = ['hmm', 'uh', 'oh', 'ah', 'so'];
        const mediumFillers = ['umm...', 'well...'];
        const longFillers = ['let-me-think', 'one-moment', 'let-me-see', 'give-me-a-moment'];
        const allFillers = [...shortFillers, ...mediumFillers, ...longFillers];
        
        // Play a random filler from available options
        function playRandomFiller(fromList = null) {
            const phrases = fromList || allFillers;
            const available = phrases.filter(f => fillerCache[f]);
            
            if (available.length === 0) {
                // Fall back to any available filler or earcon
                const anyAvailable = allFillers.filter(f => fillerCache[f]);
                if (anyAvailable.length > 0) {
                    playPersonaFiller(anyAvailable[0]);
                } else {
                    playFileEarcon('thinking');
                }
                return;
            }
            
            // Pick a different filler than last time if possible
            let index;
            if (available.length === 1) {
                index = 0;
            } else {
                do {
                    index = Math.floor(Math.random() * available.length);
                } while (index === lastFillerIndex && available.length > 1);
            }
            
            lastFillerIndex = index;
            playPersonaFiller(available[index]);
        }
        
        // Chain fillers together to fill longer waits naturally
        async function startFillerChain(expectedWaitMs) {
            if (fillerChainActive) return;
            fillerChainActive = true;
            fillerChainAbort = false;
            
            // Play initial medium filler immediately (umm..., well...)
            playRandomFiller(mediumFillers);
            
            // If expected wait is long enough, schedule follow-up fillers
            if (expectedWaitMs > 2500) {
                // Wait 0.8-1.5 seconds, then play a longer filler
                const firstDelay = 800 + Math.random() * 700;
                await sleep(firstDelay);
                
                if (!fillerChainAbort && fillerChainActive) {
                    playRandomFiller(longFillers);
                }
                
                // For very long waits (>5s), add another short filler
                if (expectedWaitMs > 5000 && !fillerChainAbort) {
                    const secondDelay = 1500 + Math.random() * 1000;
                    await sleep(secondDelay);
                    
                    if (!fillerChainAbort && fillerChainActive) {
                        playRandomFiller(shortFillers);
                    }
                }
                
                // For very long waits (>8s), add one more medium filler
                if (expectedWaitMs > 8000 && !fillerChainAbort) {
                    const thirdDelay = 1200 + Math.random() * 800;
                    await sleep(thirdDelay);
                    
                    if (!fillerChainAbort && fillerChainActive) {
                        playRandomFiller(mediumFillers);
                    }
                }
            }
            
            fillerChainActive = false;
        }
        
        // Stop filler chain when response arrives
        function stopFillerChain() {
            fillerChainAbort = true;
            fillerChainActive = false;
        }
        
        // Helper sleep function
        function sleep(ms) {
            return new Promise(resolve => setTimeout(resolve, ms));
        }
        
        // Play appropriate filler based on expected wait time
        function playWaitFiller(estimatedWaitMs, isToolCall = false) {
            // Only play fillers for longer waits
            if (estimatedWaitMs < 800) {
                return;  // Too short, no filler needed
            }
            
            if (isToolCall) {
                // Tool calls get a special earcon then chain
                playFileEarcon('tool_calling');
                // Start filler chain after the earcon
                setTimeout(() => startFillerChain(estimatedWaitMs - 500), 500);
                return;
            }
            
            // Start the filler chain - it handles timing internally
            startFillerChain(estimatedWaitMs);
        }
        
        // Update timing estimates from API response
        function updateTimingEstimates(timing) {
            if (timing && timing.estimates) {
                currentTiming = timing.estimates;
                console.log(`[Groklexa] Updated timing: trans=${currentTiming.transcription_ms}ms, infer=${currentTiming.inference_ms}ms, synth=${currentTiming.synthesis_ms}ms`);
            }
        }
        
        // Initialize earcons on page load
        preloadEarcons();

        function showResult(data) {
            let html = '';
            
            if (data.transcription) {
                html += `<div class="chat-message"><strong>You:</strong> ${data.transcription}</div>`;
                addToHistory('user', data.transcription);
            }
            
            const aiText = data.ai_response_text || data.ai_audio_transcript;
            if (aiText) {
                html += `<div class="chat-message"><strong>Groklexa:</strong> ${aiText}</div>`;
                addToHistory('assistant', aiText);
            }
            
            if (data.ai_response_audio_base64 && data.ai_response_audio_base64.length > 0) {
                try {
                    const binaryString = atob(data.ai_response_audio_base64);
                    const bytes = new Uint8Array(binaryString.length);
                    for (let i = 0; i < binaryString.length; i++) {
                        bytes[i] = binaryString.charCodeAt(i);
                    }
                    
                    const wavFile = createWavFile(bytes, 24000);
                    lastAudioBlob = wavFile;  // Store for download
                    const audioUrl = URL.createObjectURL(wavFile);
                    
                    // Show audio player in sidebar
                    audioPlayerContainer.classList.remove('hidden');
                    aiAudioPlayer.src = audioUrl;
                    
                    // Pause VAD while AI is speaking to prevent echo feedback
                    isAISpeaking = true;
                    showStatus('üîä Groklexa speaking...', 'speaking');
                    console.log('AI audio starting - pausing VAD');
                    
                    // Resume VAD when audio finishes
                    aiAudioPlayer.onended = () => {
                        isAISpeaking = false;
                        sileroAudioChunks = [];  // Clear any AI speech captured by recorder
                        console.log('AI audio ended - resuming VAD (buffer cleared)');
                        if (isVadActive) {
                            showStatus('üéß Listening for speech...', 'listening');
                        }
                    };
                    
                    // Also handle if audio is paused or errors
                    aiAudioPlayer.onerror = () => {
                        isAISpeaking = false;
                        sileroAudioChunks = [];  // Clear any AI speech captured by recorder
                        console.log('AI audio error - resuming VAD');
                    };
                    
                    aiAudioPlayer.play().catch(e => {
                        console.log('Could not auto-play audio:', e);
                        isAISpeaking = false;  // Resume VAD if playback fails
                        sileroAudioChunks = [];  // Clear any AI speech captured by recorder
                    });
                } catch (e) {
                    console.error('Error processing audio:', e);
                    isAISpeaking = false;
                    sileroAudioChunks = [];  // Clear any AI speech captured by recorder
                }
            }
            
            // Update chat log
            chatLogEmpty.style.display = 'none';
            resultContent.innerHTML = html + resultContent.innerHTML;
            
            // Scroll to top of chat log (newest messages)
            chatLogContainer.scrollTop = 0;
        }

        function createWavFile(pcm16Data, sampleRate) {
            const numChannels = 1;
            const bitsPerSample = 16;
            const byteRate = sampleRate * numChannels * (bitsPerSample / 8);
            const blockAlign = numChannels * (bitsPerSample / 8);
            const dataSize = pcm16Data.length;
            const headerSize = 44;
            const totalSize = headerSize + dataSize;
            
            const buffer = new ArrayBuffer(totalSize);
            const view = new DataView(buffer);
            
            const writeString = (offset, string) => {
                for (let i = 0; i < string.length; i++) {
                    view.setUint8(offset + i, string.charCodeAt(i));
                }
            };
            
            writeString(0, 'RIFF');
            view.setUint32(4, totalSize - 8, true);
            writeString(8, 'WAVE');
            writeString(12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true);
            view.setUint16(22, numChannels, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, byteRate, true);
            view.setUint16(32, blockAlign, true);
            view.setUint16(34, bitsPerSample, true);
            writeString(36, 'data');
            view.setUint32(40, dataSize, true);
            
            const pcmView = new Uint8Array(buffer, headerSize);
            pcmView.set(pcm16Data);
            
            return new Blob([buffer], { type: 'audio/wav' });
        }

        // ========== CONVERSATION HISTORY ==========
        
        function getHistoryKey() {
            return `groklexaHistory_${currentPersonaId}`;
        }
        
        function loadConversationHistory() {
            try {
                const saved = localStorage.getItem(getHistoryKey());
                if (saved) {
                    conversationHistory = JSON.parse(saved);
                    console.log(`Loaded conversation history for ${currentPersonaId}:`, conversationHistory.length, 'messages');
                } else {
                    conversationHistory = [];
                }
                updateChatLogUI();
            } catch (e) {
                console.error('Failed to load history:', e);
                conversationHistory = [];
            }
        }
        
        function saveConversationHistory() {
            try {
                localStorage.setItem(getHistoryKey(), JSON.stringify(conversationHistory));
            } catch (e) {
                console.error('Failed to save history:', e);
            }
        }
        
        function addToHistory(role, content) {
            conversationHistory.push({ role, content });
            saveConversationHistory();
        }
        
        function clearHistory() {
            conversationHistory = [];
            localStorage.removeItem(getHistoryKey());
            resultContent.innerHTML = '';
            result.classList.add('hidden');
            updateChatLogUI();
            console.log(`Conversation history cleared for ${currentPersonaId}`);
        }
        
        function updateChatLogUI() {
            // Update the chat log display
            if (conversationHistory.length > 0) {
                chatLogContainer.classList.remove('hidden');
                chatLogEmpty.classList.add('hidden');
            } else {
                chatLogContainer.classList.add('hidden');
                chatLogEmpty.classList.remove('hidden');
            }
        }
        
        // Alias for persona switching
        function loadHistory() {
            loadConversationHistory();
        }
        
        loadConversationHistory();
        
        document.getElementById('clearHistoryBtn').addEventListener('click', () => {
            if (confirm('Clear conversation history?')) {
                clearHistory();
                chatLogEmpty.style.display = 'block';
            }
        });
        
        // Copy conversation to clipboard
        copyLogBtn.addEventListener('click', () => {
            let text = '';
            conversationHistory.forEach(msg => {
                const role = msg.role === 'user' ? 'You' : 'Groklexa';
                text += `${role}: ${msg.content}\n\n`;
            });
            
            if (text) {
                navigator.clipboard.writeText(text.trim()).then(() => {
                    copyLogBtn.style.background = 'rgba(76, 175, 80, 0.3)';
                    setTimeout(() => {
                        copyLogBtn.style.background = '';
                    }, 1000);
                }).catch(err => {
                    console.error('Failed to copy:', err);
                });
            }
        });
        
        // Download last audio
        downloadAudioBtn.addEventListener('click', () => {
            if (lastAudioBlob) {
                const url = URL.createObjectURL(lastAudioBlob);
                const a = document.createElement('a');
                a.href = url;
                // Determine file extension from MIME type
                let ext = 'wav';
                if (lastAudioBlob.type === 'audio/mpeg') ext = 'mp3';
                else if (lastAudioBlob.type === 'audio/wav') ext = 'wav';
                else if (lastAudioBlob.type === 'audio/webm') ext = 'webm';
                a.download = `groklexa-response-${Date.now()}.${ext}`;
                document.body.appendChild(a);
                a.click();
                document.body.removeChild(a);
                URL.revokeObjectURL(url);
            }
        });

        // ========== WAKE WORD FUNCTIONS ==========
        
        const tagline = document.getElementById('tagline');
        const listenToggle = document.getElementById('listenToggle');
        const listenLabels = document.querySelectorAll('.listen-label');
        
        const TAGLINE_DEFAULT = 'Configurable AI voice wrapper';
        const TAGLINE_LOADING = 'Loading wake word models...';
        const TAGLINE_LISTENING = 'Say "Groklexa" to wake';
        const TAGLINE_ACTIVE = 'Say "Groklexa" again to sleep';
        const TAGLINE_ERROR = 'Microphone access required';
        
        function setWakeWordState(newState, message = null) {
            wakeWordState = newState;
            
            // Update tagline
            tagline.className = 'subtitle';
            if (newState === 'loading') {
                tagline.textContent = message || TAGLINE_LOADING;
            } else if (newState === 'sleeping') {
                tagline.textContent = TAGLINE_LISTENING;
                tagline.classList.add('listening');
            } else if (newState === 'active') {
                tagline.textContent = TAGLINE_ACTIVE;
                tagline.classList.add('active');
            } else if (newState === 'off') {
                tagline.textContent = TAGLINE_DEFAULT;
            }
            
            // Update toggle labels
            listenLabels.forEach(label => {
                label.classList.remove('active');
                if (label.classList.contains('ignore') && (newState === 'off' || newState === 'loading')) {
                    label.classList.add('active');
                } else if (label.classList.contains('listen') && (newState === 'sleeping' || newState === 'active')) {
                    label.classList.add('active');
                }
            });
        }
        
        async function loadWakeWordModels() {
            try {
                setWakeWordState('loading', 'Loading wake word models...');
                listenToggle.disabled = true;
                
                const sessionOptions = { executionProviders: ['wasm'] };
                
                const [melspec, embedding, vadModel, wakeword] = await Promise.all([
                    ort.InferenceSession.create('/static/openwakeword/models/melspectrogram.onnx', sessionOptions),
                    ort.InferenceSession.create('/static/openwakeword/models/embedding_model.onnx', sessionOptions),
                    ort.InferenceSession.create('/static/openwakeword/models/silero_vad.onnx', sessionOptions),
                    ort.InferenceSession.create('/static/openwakeword/models/groklexa.onnx', sessionOptions)
                ]);
                
                wakeWordModels.melspec = melspec;
                wakeWordModels.embedding = embedding;
                wakeWordModels.vad = vadModel;
                wakeWordModels.wakeword = wakeword;
                
                wakeWordSuccessSound = new Audio('/static/openwakeword/success.mp3');
                wakeWordSuccessSound.preload = 'auto';
                
                console.log('Wake word models loaded successfully');
                return true;
            } catch (error) {
                console.error('Failed to load wake word models:', error);
                setWakeWordState('loading', 'Failed to load: ' + error.message);
                listenToggle.disabled = true;
                return false;
            }
        }
        
        function resetWakeWordState() {
            ww_mel_buffer = [];
            ww_embedding_buffer = [];
            for (let i = 0; i < 16; i++) {
                ww_embedding_buffer.push(new Float32Array(96).fill(0));
            }
            const vadStateShape = [2, 1, 64];
            if (!ww_vadState.h) {
                ww_vadState.h = new ort.Tensor('float32', new Float32Array(128).fill(0), vadStateShape);
                ww_vadState.c = new ort.Tensor('float32', new Float32Array(128).fill(0), vadStateShape);
            } else {
                ww_vadState.h.data.fill(0);
                ww_vadState.c.data.fill(0);
            }
            ww_isSpeechActive = false;
            ww_vadHangoverCounter = 0;
            ww_isDetectionCoolingDown = false;
        }
        
        async function runWakeWordVAD(chunk) {
            try {
                const tensor = new ort.Tensor('float32', chunk, [1, chunk.length]);
                const sr = new ort.Tensor('int64', [BigInt(WW_SAMPLE_RATE)], []);
                const res = await wakeWordModels.vad.run({ 
                    input: tensor, 
                    sr: sr, 
                    h: ww_vadState.h, 
                    c: ww_vadState.c 
                });
                ww_vadState.h = res.hn;
                ww_vadState.c = res.cn;
                return res.output.data[0] > 0.5;
            } catch (err) {
                console.error("Wake word VAD Error:", err);
                return false;
            }
        }
        
        async function runWakeWordInference(chunk, isSpeechActive) {
            const melspecTensor = new ort.Tensor('float32', chunk, [1, WW_FRAME_SIZE]);
            const melspecResults = await wakeWordModels.melspec.run({ 
                [wakeWordModels.melspec.inputNames[0]]: melspecTensor 
            });
            let new_mel_data = melspecResults[wakeWordModels.melspec.outputNames[0]].data;
            
            for (let j = 0; j < new_mel_data.length; j++) {
                new_mel_data[j] = (new_mel_data[j] / 10.0) + 2.0;
            }
            
            for (let j = 0; j < 5; j++) {
                ww_mel_buffer.push(new Float32Array(new_mel_data.subarray(j * 32, (j + 1) * 32)));
            }
            
            while (ww_mel_buffer.length >= 76) {
                const window_frames = ww_mel_buffer.slice(0, 76);
                const flattened_mel = new Float32Array(76 * 32);
                for (let j = 0; j < window_frames.length; j++) {
                    flattened_mel.set(window_frames[j], j * 32);
                }
                
                const embeddingFeeds = { 
                    [wakeWordModels.embedding.inputNames[0]]: new ort.Tensor('float32', flattened_mel, [1, 76, 32, 1]) 
                };
                const embeddingOut = await wakeWordModels.embedding.run(embeddingFeeds);
                const new_embedding = embeddingOut[wakeWordModels.embedding.outputNames[0]].data;
                
                ww_embedding_buffer.shift();
                ww_embedding_buffer.push(new Float32Array(new_embedding));
                
                const flattened_embeddings = new Float32Array(16 * 96);
                for (let j = 0; j < ww_embedding_buffer.length; j++) {
                    flattened_embeddings.set(ww_embedding_buffer[j], j * 96);
                }
                const final_input_tensor = new ort.Tensor('float32', flattened_embeddings, [1, 16, 96]);
                
                const results = await wakeWordModels.wakeword.run({ 
                    [wakeWordModels.wakeword.inputNames[0]]: final_input_tensor 
                });
                const score = results[wakeWordModels.wakeword.outputNames[0]].data[0];
                
                // Only detect wake word if:
                // 1. Score threshold met
                // 2. Speech is active (from Silero VAD)
                // 3. Not in cooldown period
                // 4. AI is NOT speaking (prevent false trigger from AI's voice)
                if (score > 0.5 && isSpeechActive && !ww_isDetectionCoolingDown && !isAISpeaking) {
                    console.log('üéâ Wake word detected! Score:', score.toFixed(3));
                    onWakeWordDetected();
                    ww_isDetectionCoolingDown = true;
                    setTimeout(() => { ww_isDetectionCoolingDown = false; }, 2000);
                }
                
                ww_mel_buffer.splice(0, 8);
            }
        }
        
        function onWakeWordDetected() {
            if (wakeWordSuccessSound) {
                wakeWordSuccessSound.play().catch(e => console.log('Could not play sound:', e));
            }
            
            if (wakeWordState === 'sleeping') {
                setWakeWordState('active');
                activateConversationMode();
                playVideoForward();  // She wakes up
            } else if (wakeWordState === 'active') {
                setWakeWordState('sleeping');
                deactivateConversationMode();
                playVideoBackward();  // She goes back to sleep
            }
        }
        
        function activateConversationMode() {
            console.log('üé§ Conversation mode activated');
            
            // Initialize Silero-based recording (uses neural network for speech detection)
            if (!sileroRecorder && wakeWordStream) {
                initSileroRecorder();
            }
            
            // Start continuous recording to capture all audio (WebM needs complete container)
            sileroAudioChunks = [];
            if (sileroRecorder && sileroRecorder.state === 'inactive') {
                sileroRecorder.start(100);  // Collect chunks every 100ms
                console.log('üìº Continuous recording started for conversation mode');
            }
            
            // Start browser transcription if using separate APIs with browser transcription
            if (currentApiConfig?.mode === 'separate' && 
                currentApiConfig?.transcription?.provider === 'browser') {
                console.log('[Groklexa] Starting parallel browser transcription');
                browserTranscriptBuffer = '';  // Clear any stale transcripts
                startBrowserTranscription();
            }
            
            // Reset state
            sileroWasSpeaking = false;
            sileroAudioChunks = [];
            isProcessing = false;
            
            showStatus('üéß Listening for speech... (AI-powered)', 'listening');
        }
        
        function deactivateConversationMode() {
            console.log('üò¥ Going to sleep');
            
            wakeWordAborted = true;
            
            if (currentAbortController) {
                console.log('Aborting pending inference request');
                currentAbortController.abort();
                currentAbortController = null;
            }
            
            // Stop browser transcription if running
            stopBrowserTranscription();
            
            isProcessing = false;
            isSpeaking = false;
            silenceStart = null;
            
            // Stop Silero-based recording
            if (sileroRecorder && sileroRecorder.state === 'recording') {
                sileroRecorder.stop();
            }
            sileroAudioChunks = [];
            sileroWasSpeaking = false;
            
            // Stop manual recording
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
            }
            audioChunks = [];
            
            // Stop volume-based VAD (fallback)
            if (vadMediaRecorder && vadMediaRecorder.state === 'recording') {
                vadMediaRecorder.stop();
            }
            vadAudioChunks = [];
            
            if (isVadActive && vadToggle) {
                vadToggle.checked = false;
                vadToggle.dispatchEvent(new Event('change'));
            }
            
            setTimeout(() => { wakeWordAborted = false; }, 500);
        }
        
        const wakeWordProcessorCode = `
            class WakeWordProcessor extends AudioWorkletProcessor {
                bufferSize = 1280;
                _buffer = new Float32Array(this.bufferSize);
                _pos = 0;
                constructor() { super(); }
                process(inputs) {
                    const input = inputs[0][0];
                    if (input) {
                        for (let i = 0; i < input.length; i++) {
                            this._buffer[this._pos++] = input[i];
                            if (this._pos === this.bufferSize) {
                                this.port.postMessage(this._buffer.slice());
                                this._pos = 0;
                            }
                        }
                    }
                    return true;
                }
            }
            registerProcessor('wakeword-processor', WakeWordProcessor);
        `;
        
        async function startWakeWordListening() {
            try {
                resetWakeWordState();
                
                wakeWordStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                wakeWordAudioContext = new AudioContext({ sampleRate: WW_SAMPLE_RATE });
                const source = wakeWordAudioContext.createMediaStreamSource(wakeWordStream);
                
                const blob = new Blob([wakeWordProcessorCode], { type: 'application/javascript' });
                const workletURL = URL.createObjectURL(blob);
                await wakeWordAudioContext.audioWorklet.addModule(workletURL);
                wakeWordWorkletNode = new AudioWorkletNode(wakeWordAudioContext, 'wakeword-processor');
                
                wakeWordWorkletNode.port.onmessage = async (event) => {
                    const chunk = event.data;
                    if (!chunk || wakeWordState === 'loading') return;
                    
                    const vadFired = await runWakeWordVAD(chunk);
                    
                    if (vadFired) {
                        if (!ww_isSpeechActive) { }
                        ww_isSpeechActive = true;
                        ww_vadHangoverCounter = WW_VAD_HANGOVER_FRAMES;
                    } else if (ww_isSpeechActive) {
                        ww_vadHangoverCounter--;
                        if (ww_vadHangoverCounter <= 0) {
                            ww_isSpeechActive = false;
                        }
                    }
                    
                    // In conversation mode, use Silero VAD for speech-based recording
                    if (wakeWordState === 'active' && !isProcessing && !isAISpeaking) {
                        handleSileroSpeechState(ww_isSpeechActive);
                    }
                    
                    await runWakeWordInference(chunk, ww_isSpeechActive);
                };
                
                source.connect(wakeWordWorkletNode);
                wakeWordWorkletNode.connect(wakeWordAudioContext.destination);
                
                setWakeWordState('sleeping');
                console.log('Wake word listening started');
                
            } catch (error) {
                console.error('Failed to start wake word listening:', error.name, error.message, error);
                let errorMsg = error.message || error.name || 'Unknown error';
                if (error.name === 'NotAllowedError') {
                    errorMsg = 'Microphone access denied';
                } else if (error.name === 'NotFoundError') {
                    errorMsg = 'No microphone found';
                }
                setWakeWordState('loading', 'Error: ' + errorMsg);
                listenToggle.checked = false;
            }
        }
        
        let wakeWordModelsLoaded = false;
        
        async function initWakeWord() {
            wakeWordModelsLoaded = await loadWakeWordModels();
            if (wakeWordModelsLoaded) {
                setWakeWordState('off');
                listenToggle.disabled = false;
            }
        }
        
        // Listen toggle event handler
        listenToggle.addEventListener('change', async () => {
            if (listenToggle.checked) {
                // Turn on listening
                if (!wakeWordModelsLoaded) {
                    listenToggle.checked = false;
                    return;
                }
                if (!wakeWordAudioContext) {
                    await startWakeWordListening();
                } else {
                    setWakeWordState('sleeping');
                }
            } else {
                // Turn off listening
                stopWakeWordListening();
                setWakeWordState('off');
            }
        });
        
        function stopWakeWordListening() {
            if (wakeWordState === 'active') {
                deactivateConversationMode();
            }
            
            if (wakeWordWorkletNode) {
                wakeWordWorkletNode.disconnect();
                wakeWordWorkletNode = null;
            }
            
            if (wakeWordStream) {
                wakeWordStream.getTracks().forEach(track => track.stop());
                wakeWordStream = null;
            }
            
            if (wakeWordAudioContext) {
                wakeWordAudioContext.close();
                wakeWordAudioContext = null;
            }
            
            wakeWordState = 'off';
            console.log('Wake word listening stopped');
        }
        
        window.addEventListener('DOMContentLoaded', () => {
            setTimeout(initWakeWord, 500);
        });

        // ========== SILERO VAD-BASED RECORDING ==========
        // Uses neural network to detect actual speech, not just any sound
        
        function initSileroRecorder() {
            if (!wakeWordStream) {
                console.error('Cannot init Silero recorder - no wake word stream');
                return false;
            }
            
            try {
                sileroRecorder = new MediaRecorder(wakeWordStream);
                sileroAudioChunks = [];
                
                sileroRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        // Always add to audio chunks - we'll use all of them
                        // This ensures the WebM container is always valid
                        sileroAudioChunks.push(event.data);
                    }
                };
                
                sileroRecorder.onstop = async () => {
                    if (wakeWordAborted) {
                        console.log('Silero recording aborted by wake word, discarding');
                        sileroAudioChunks = [];
                        isProcessing = false;
                        // Create fresh recorder for next session
                        sileroRecorder = null;
                        if (wakeWordState === 'active') {
                            initSileroRecorder();
                            startContinuousRecording();
                        }
                        return;
                    }
                    
                    const speechDuration = Date.now() - (sileroSpeechStartTime || Date.now());
                    
                    if (sileroAudioChunks.length > 0 && speechDuration >= SILERO_MIN_SPEECH_DURATION) {
                        console.log(`Silero VAD: Creating blob from ${sileroAudioChunks.length} chunks`);
                        const audioBlob = new Blob(sileroAudioChunks, { type: 'audio/webm' });
                        sileroAudioChunks = [];
                        
                        if (audioBlob.size > 1000) {
                            console.log(`Silero VAD: Processing ${audioBlob.size} bytes, ${speechDuration}ms of speech`);
                            const audioUrl = URL.createObjectURL(audioBlob);
                            audioPlayer.src = audioUrl;
                            audioPreview.classList.remove('hidden');
                            
                            await processAudioBlob(audioBlob);
                        } else {
                            console.log(`Silero VAD: Audio too small (${audioBlob.size} bytes), ignoring`);
                            isProcessing = false;
                        }
                    } else {
                        console.log(`Silero VAD: Speech too short (${speechDuration}ms) or no chunks (${sileroAudioChunks.length}), ignoring`);
                        sileroAudioChunks = [];
                        isProcessing = false;
                    }
                    
                    // Create FRESH MediaRecorder for next utterance (avoids WebM container issues)
                    sileroRecorder = null;
                    if (wakeWordState === 'active') {
                        sileroAudioChunks = [];
                        initSileroRecorder();
                        startContinuousRecording();
                        console.log('üìº Fresh recorder created for next utterance');
                    }
                    
                    if (wakeWordState === 'active' && !isProcessing) {
                        showStatus('üéß Listening for speech...', 'listening');
                    }
                };
                
                console.log('Silero recorder initialized');
                return true;
            } catch (e) {
                console.error('Failed to init Silero recorder:', e);
                return false;
            }
        }
        
        function handleSileroSpeechState(isSpeaking) {
            // Detect speech state transitions
            if (isSpeaking && !sileroWasSpeaking) {
                // Speech started!
                console.log('üé§ Silero VAD: Speech started');
                sileroWasSpeaking = true;
                sileroSpeechStartTime = Date.now();
                
                // Recorder should already be running and collecting chunks
                // We just mark the speech start time - chunks are already being collected
                if (sileroRecorder && sileroRecorder.state === 'recording') {
                    console.log(`üì¶ Recording in progress, ${sileroAudioChunks.length} chunks so far`);
                } else {
                    // Recorder not running - start fresh
                    console.log('‚ö†Ô∏è Recorder was not running, starting now');
                    sileroAudioChunks = [];
                    if (!sileroRecorder) {
                        initSileroRecorder();
                    }
                    if (sileroRecorder && sileroRecorder.state === 'inactive') {
                        sileroRecorder.start(100);
                    }
                }
                
                showStatus('üé§ Listening...', 'speaking');
            } else if (!isSpeaking && sileroWasSpeaking) {
                // Speech ended!
                console.log('üõë Silero VAD: Speech ended');
                sileroWasSpeaking = false;
                isProcessing = true;
                
                // Stop recording - all chunks since start will be used
                if (sileroRecorder && sileroRecorder.state === 'recording') {
                    showStatus('Processing your speech...', 'processing');
                    sileroRecorder.stop();
                }
            }
        }
        
        // Start continuous recording (captures all audio for valid WebM container)
        function startContinuousRecording() {
            if (!wakeWordStream) {
                console.error('Cannot start recording - no wake word stream');
                return;
            }
            
            // Create recorder if it doesn't exist
            if (!sileroRecorder) {
                initSileroRecorder();
            }
            
            // If recorder exists and is inactive, start it
            if (sileroRecorder && sileroRecorder.state === 'inactive') {
                sileroAudioChunks = [];
                sileroRecorder.start(100);  // Collect chunks every 100ms
                console.log('üìº Continuous recording started');
            }
        }
        
        // Stop continuous recording
        function stopContinuousRecording() {
            sileroAudioChunks = [];
        }

        // ========== SIMPLE VAD (fallback) ==========
        
        let vadStream = null;
        let vadAudioContext = null;
        let vadAnalyser = null;
        let vadMediaRecorder = null;
        let vadAudioChunks = [];
        let isSpeaking = false;
        let silenceStart = null;
        let vadAnimationFrame = null;
        
        const VAD_CONFIG = {
            speechThreshold: 25,
            silenceThreshold: 15,
            silenceDuration: 1200,
            minSpeechDuration: 500
        };
        
        let speechStartTime = null;
        
        function checkVoiceActivity() {
            // Skip detection if VAD is off, processing, or AI is speaking (prevent echo)
            if (!isVadActive || isProcessing || isAISpeaking) {
                vadAnimationFrame = requestAnimationFrame(checkVoiceActivity);
                return;
            }
            
            const dataArray = new Uint8Array(vadAnalyser.frequencyBinCount);
            vadAnalyser.getByteFrequencyData(dataArray);
            
            let sum = 0;
            for (let i = 0; i < dataArray.length; i++) {
                sum += dataArray[i];
            }
            const volume = sum / dataArray.length;
            
            const now = Date.now();
            
            if (!isSpeaking) {
                if (volume > VAD_CONFIG.speechThreshold) {
                    isSpeaking = true;
                    silenceStart = null;
                    speechStartTime = Date.now();
                    
                    vadAudioChunks = [];
                    if (vadMediaRecorder.state === 'inactive') {
                        // Use timeslice of 100ms to collect data periodically
                        // This ensures chunks are captured even for short recordings
                        vadMediaRecorder.start(100);
                    }
                    
                    console.log('üé§ Speech detected, volume:', volume.toFixed(1));
                    showStatus('üé§ Listening...', 'speaking');
                }
            } else {
                if (volume < VAD_CONFIG.silenceThreshold) {
                    if (!silenceStart) {
                        silenceStart = now;
                    } else if (now - silenceStart > VAD_CONFIG.silenceDuration) {
                        const speechDuration = now - speechStartTime;
                        
                        if (speechDuration >= VAD_CONFIG.minSpeechDuration) {
                            isSpeaking = false;
                            silenceStart = null;
                            isProcessing = true;
                            
                            console.log('üõë Silence detected, processing...');
                            showStatus('Processing your speech...', 'processing');
                            
                            if (vadMediaRecorder.state === 'recording') {
                                vadMediaRecorder.stop();
                            }
                        } else {
                            console.log('Speech too short, resetting');
                            isSpeaking = false;
                            silenceStart = null;
                            vadAudioChunks = [];
                            if (vadMediaRecorder.state === 'recording') {
                                vadMediaRecorder.stop();
                            }
                        }
                    }
                } else {
                    silenceStart = null;
                }
            }
            
            vadAnimationFrame = requestAnimationFrame(checkVoiceActivity);
        }
        
        function stopVAD() {
            if (vadAnimationFrame) {
                cancelAnimationFrame(vadAnimationFrame);
                vadAnimationFrame = null;
            }
            
            if (vadMediaRecorder && vadMediaRecorder.state === 'recording') {
                vadMediaRecorder.stop();
            }
            
            if (vadStream) {
                vadStream.getTracks().forEach(track => track.stop());
                vadStream = null;
            }
            
            if (vadAudioContext) {
                vadAudioContext.close();
                vadAudioContext = null;
            }
            
            isSpeaking = false;
            silenceStart = null;
            isProcessing = false;
        }
        
        async function startVAD() {
            try {
                vadStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                vadAudioContext = new AudioContext();
                const source = vadAudioContext.createMediaStreamSource(vadStream);
                
                vadAnalyser = vadAudioContext.createAnalyser();
                vadAnalyser.fftSize = 256;
                vadAnalyser.smoothingTimeConstant = 0.5;
                source.connect(vadAnalyser);
                
                vadMediaRecorder = new MediaRecorder(vadStream);
                vadAudioChunks = [];
                
                vadMediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        vadAudioChunks.push(event.data);
                    }
                };
                
                vadMediaRecorder.onstop = async () => {
                    if (wakeWordAborted) {
                        console.log('VAD recording aborted by wake word, discarding');
                        vadAudioChunks = [];
                        isProcessing = false;
                        return;
                    }
                    
                    if (vadAudioChunks.length > 0) {
                        const audioBlob = new Blob(vadAudioChunks, { type: 'audio/webm' });
                        vadAudioChunks = [];
                        
                        if (audioBlob.size > 1000) {
                            const audioUrl = URL.createObjectURL(audioBlob);
                            audioPlayer.src = audioUrl;
                            audioPreview.classList.remove('hidden');
                            
                            await processAudioBlob(audioBlob);
                        } else {
                            console.log('Audio too short, ignoring');
                            isProcessing = false;  // Reset so VAD can detect again
                        }
                    } else {
                        // No audio chunks collected - reset processing state
                        console.log('No audio chunks collected');
                        isProcessing = false;
                    }
                    
                    if (isVadActive && !isProcessing) {
                        showStatus('üéß Listening for speech...', 'listening');
                    }
                };
                
                checkVoiceActivity();
                showStatus('üéß Listening for speech...', 'listening');
                return true;
                
            } catch (error) {
                console.error('Failed to initialize VAD:', error);
                showStatus('Microphone error: ' + error.message, 'error');
                vadToggle.checked = false;
                return false;
            }
        }

        // ========== AUDIO PROCESSING ==========
        
        async function processAudioBlob(blob) {
            if (wakeWordAborted) {
                console.log('[Groklexa] Recording aborted by wake word, discarding audio');
                isProcessing = false;
                return;
            }
            
            // Check if we should use separate APIs
            const useSeparateAPIs = currentApiConfig && currentApiConfig.mode === 'separate';
            
            if (useSeparateAPIs) {
                console.log('[Groklexa] Using separate APIs mode');
                await processWithSeparateAPIs(blob);
                return;
            }
            
            // Default: Use unified WebSocket API
            console.log('[Groklexa] Using unified WebSocket API');
            await processWithUnifiedAPI(blob);
        }
        
        async function processWithUnifiedAPI(blob) {
            const formData = new FormData();
            const audioFile = new File([blob], 'recording.mp3', { type: 'audio/mpeg' });
            formData.append('audio', audioFile);
            formData.append('voice', document.getElementById('singleVoice')?.value || 'Ara');
            formData.append('conversation_history', JSON.stringify(conversationHistory));
            
            currentAbortController = new AbortController();
            
            // Set a 60 second timeout for the request
            const timeoutId = setTimeout(() => {
                console.log('[Groklexa] Request timeout after 60s, aborting...');
                currentAbortController.abort();
            }, 60000);
            
            try {
                let response = await fetch('/api/infer/websocket', {
                    method: 'POST',
                    body: formData,
                    signal: currentAbortController.signal
                });
                
                clearTimeout(timeoutId);
                
                if (wakeWordAborted) {
                    console.log('[Groklexa] Request completed but wake word aborted, discarding result');
                    isProcessing = false;
                    return;
                }
                
                const data = await response.json();
                
                if (data.success) {
                    showStatus('Success!', 'success');
                    showResult(data.result);
                } else {
                    showStatus('Error: ' + data.error, 'error');
                    console.error('[Groklexa] Inference error:', data);
                }
            } catch (error) {
                if (error.name === 'AbortError') {
                    console.log('Inference request aborted');
                    showStatus('Stopped', 'info');
                } else {
                    showStatus('Error: ' + error.message, 'error');
                    console.error('Request error:', error);
                }
            } finally {
                clearTimeout(timeoutId);  // Clear timeout if not already fired
                currentAbortController = null;
                isProcessing = false;
                if (isVadActive) {
                    showStatus('üéß Listening for speech...', 'listening');
                }
            }
        }
        
        async function processWithSeparateAPIs(blob) {
            console.log('[Groklexa] Starting separate API pipeline');
            showStatus('üé§ Transcribing...', 'processing');
            
            try {
                // Step 1: Transcription (browser or server based on config)
                let transcription;
                const transConfig = currentApiConfig?.transcription;
                
                if (transConfig?.provider === 'browser') {
                    // Use Web Speech API for live transcription
                    console.log('[Groklexa] Using browser speech recognition');
                    transcription = await transcribeWithWebSpeech(blob);
                } else if (transConfig?.provider === 'local_whisper') {
                    // Use local Whisper model
                    console.log('[Groklexa] Using local Whisper transcription');
                    transcription = await transcribeWithServer(blob);
                } else {
                    // Use server-side transcription API
                    console.log('[Groklexa] Using server-side transcription:', transConfig?.provider);
                    transcription = await transcribeWithServer(blob);
                }
                
                if (!transcription || transcription.trim() === '') {
                    console.log('[Groklexa] No transcription result, skipping inference');
                    showStatus('No speech detected', 'info');
                    isProcessing = false;
                    return;
                }
                
                console.log('[Groklexa] Transcription:', transcription);
                
                // Step 2: Text inference via server
                showStatus('ü§î Thinking...', 'processing');
                
                // Start filler chain based on expected wait time
                const expectedInferenceMs = currentTiming.inference_ms || 2000;
                if (expectedInferenceMs > 1500) {
                    // Start a chain of fillers to fill the wait naturally
                    startFillerChain(expectedInferenceMs);
                } else if (expectedInferenceMs > 800) {
                    // Short wait - just play thinking earcon
                    playFileEarcon('thinking');
                }
                
                currentAbortController = new AbortController();
                const timeoutId = setTimeout(() => {
                    console.log('[Groklexa] Inference timeout after 60s');
                    currentAbortController.abort();
                }, 60000);
                
                const response = await fetch('/api/infer/text', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        text: transcription,
                        conversation_history: conversationHistory
                    }),
                    signal: currentAbortController.signal
                });
                
                clearTimeout(timeoutId);
                
                if (wakeWordAborted) {
                    console.log('[Groklexa] Aborted during inference');
                    isProcessing = false;
                    return;
                }
                
                const data = await response.json();
                
                if (!data.success) {
                    throw new Error(data.error || 'Inference failed');
                }
                
                const aiResponse = data.response;
                const toolsCalled = data.tools_called || [];
                const memoryFlair = data.memory_flair || {};
                
                // Update timing estimates
                if (data.timing) {
                    updateTimingEstimates(data.timing);
                }
                
                // Log memory_flair decision
                if (memoryFlair.state) {
                    console.log(`[Groklexa] MemoryFlair: state=${memoryFlair.state}, tiers=${memoryFlair.tiers?.join(',')}, score=${memoryFlair.score}, deterministic=${memoryFlair.deterministic}`);
                }
                
                // Play earcon if specified (prefer file-based)
                if (memoryFlair.earcon) {
                    if (earconCache[memoryFlair.earcon]) {
                        playFileEarcon(memoryFlair.earcon);
                    } else {
                        playEarcon(memoryFlair.earcon);  // Fall back to synthesized
                    }
                }
                
                // Stop any playing filler chain - response arrived!
                stopFillerChain();
                
                console.log('[Groklexa] AI Response:', aiResponse.substring(0, 100) + '...');
                if (toolsCalled.length > 0) {
                    console.log('[Groklexa] Tools called:', toolsCalled);
                    showStatus(`üîß Tools: ${toolsCalled.join(', ')}`, 'info');
                    // Brief pause to show the tools status
                    await new Promise(resolve => setTimeout(resolve, 1500));
                }
                
                // Show results
                showResult({
                    transcription: transcription,
                    ai_response_text: aiResponse,
                    tools_called: toolsCalled
                });
                
                // Step 3: Synthesis (browser or server based on config)
                // Play "speaking" earcon before synthesis starts
                playFileEarcon('speaking');
                
                const synthConfig = currentApiConfig?.synthesis;
                if (synthConfig?.provider === 'browser') {
                    console.log('[Groklexa] Using browser speech synthesis');
                    showStatus('üîä Speaking...', 'speaking');
                    await synthesizeWithWebSpeech(aiResponse);
                } else if (synthConfig?.provider === 'edge_tts' || synthConfig?.provider === 'openai_tts' || synthConfig?.provider === 'chatterbox') {
                    console.log('[Groklexa] Using server-side synthesis:', synthConfig.provider);
                    showStatus('üîä Speaking...', 'speaking');
                    await synthesizeWithServer(aiResponse);
                } else {
                    // Fall back to browser synthesis for unsupported providers
                    console.log('[Groklexa] Falling back to browser synthesis');
                    showStatus('üîä Speaking...', 'speaking');
                    await synthesizeWithWebSpeech(aiResponse);
                }
                
                showStatus('Success!', 'success');
                
            } catch (error) {
                stopFillerChain();  // Stop fillers on error
                if (error.name === 'AbortError') {
                    console.log('[Groklexa] Request aborted');
                    showStatus('Stopped', 'info');
                } else {
                    console.error('[Groklexa] Pipeline error:', error);
                    showStatus('Error: ' + error.message, 'error');
                }
            } finally {
                currentAbortController = null;
                isProcessing = false;
                if (wakeWordState === 'active') {
                    showStatus('üéß Listening for speech...', 'listening');
                }
            }
        }
        
        // Server-side transcription API
        async function transcribeWithServer(audioBlob) {
            const formData = new FormData();
            const audioFile = new File([audioBlob], 'recording.webm', { type: 'audio/webm' });
            formData.append('audio', audioFile);
            
            const response = await fetch('/api/transcribe', {
                method: 'POST',
                body: formData,
                signal: currentAbortController?.signal
            });
            
            const data = await response.json();
            
            if (!data.success) {
                if (data.use_browser) {
                    // Fallback to browser
                    console.log('[Groklexa] Server requested browser transcription');
                    return await transcribeWithWebSpeech(audioBlob);
                }
                throw new Error(data.error || 'Transcription failed');
            }
            
            // Update timing estimates
            if (data.timing) {
                updateTimingEstimates(data.timing);
            }
            
            return data.transcription || '';
        }
        
        // Browser-based transcription using Web Speech API
        // This runs in parallel with recording, storing results as they come
        let browserTranscriptBuffer = '';
        let browserRecognition = null;
        
        function startBrowserTranscription() {
            if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
                console.warn('[Groklexa] Web Speech API not supported');
                return false;
            }
            
            if (browserRecognition) {
                return true; // Already running
            }
            
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            browserRecognition = new SpeechRecognition();
            
            browserRecognition.continuous = true;
            browserRecognition.interimResults = false;
            browserRecognition.lang = 'en-US';
            
            browserTranscriptBuffer = '';
            
            browserRecognition.onresult = (event) => {
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    if (event.results[i].isFinal) {
                        browserTranscriptBuffer += event.results[i][0].transcript + ' ';
                        console.log('[Groklexa] Browser transcription (live):', event.results[i][0].transcript);
                    }
                }
            };
            
            browserRecognition.onerror = (event) => {
                if (event.error !== 'no-speech' && event.error !== 'aborted') {
                    console.error('[Groklexa] Speech recognition error:', event.error);
                }
            };
            
            browserRecognition.onend = () => {
                console.log('[Groklexa] Browser recognition ended');
                // Restart if still in active mode
                if (wakeWordState === 'active' && currentApiConfig?.mode === 'separate' && 
                    currentApiConfig?.transcription?.provider === 'browser') {
                    setTimeout(() => {
                        if (wakeWordState === 'active' && browserRecognition) {
                            try {
                                browserRecognition.start();
                            } catch (e) {
                                // Already started or other error
                            }
                        }
                    }, 100);
                }
            };
            
            console.log('[Groklexa] Starting continuous browser transcription');
            browserRecognition.start();
            return true;
        }
        
        function stopBrowserTranscription() {
            if (browserRecognition) {
                browserRecognition.stop();
                browserRecognition = null;
            }
        }
        
        function getBrowserTranscript() {
            const transcript = browserTranscriptBuffer.trim();
            browserTranscriptBuffer = '';  // Clear for next utterance
            return transcript;
        }
        
        // Get browser transcript and clear buffer for next utterance
        // Waits a moment for any pending transcription to complete
        async function transcribeWithWebSpeech(audioBlob) {
            // Wait for pending transcription to arrive (browser API is async)
            let attempts = 0;
            const maxAttempts = 10;
            const delayMs = 200;
            
            while (attempts < maxAttempts) {
                const transcript = browserTranscriptBuffer.trim();
                if (transcript.length > 0) {
                    console.log('[Groklexa] Retrieved browser transcript:', transcript);
                    browserTranscriptBuffer = '';
                    return transcript;
                }
                
                // Wait and try again
                await new Promise(resolve => setTimeout(resolve, delayMs));
                attempts++;
                
                if (attempts < maxAttempts) {
                    console.log(`[Groklexa] Waiting for browser transcription... (${attempts}/${maxAttempts})`);
                }
            }
            
            // Final attempt
            const transcript = getBrowserTranscript();
            console.log('[Groklexa] Retrieved browser transcript (final):', transcript);
            return transcript;
        }
        
        // Server-side speech synthesis (Edge TTS, OpenAI TTS, etc.)
        async function synthesizeWithServer(text) {
            console.log('[Groklexa] Calling server synthesis API');
            
            const response = await fetch('/api/synthesize', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ text })
            });
            
            const data = await response.json();
            
            if (!data.success) {
                throw new Error(data.error || 'Synthesis failed');
            }
            
            // Update timing estimates
            if (data.timing) {
                updateTimingEstimates(data.timing);
            }
            
            if (data.use_browser) {
                // Server requested browser fallback
                console.log('[Groklexa] Server requested browser synthesis fallback');
                return synthesizeWithWebSpeech(text);
            }
            
            if (data.audio_base64) {
                // Play the audio
                console.log('[Groklexa] Playing server-generated audio');
                return playServerAudio(data.audio_base64, data.audio_format || 'mp3');
            }
            
            throw new Error('No audio received from server');
        }
        
        // Play audio from server (base64 encoded)
        function playServerAudio(base64Audio, format) {
            return new Promise((resolve, reject) => {
                try {
                    const binaryString = atob(base64Audio);
                    const bytes = new Uint8Array(binaryString.length);
                    for (let i = 0; i < binaryString.length; i++) {
                        bytes[i] = binaryString.charCodeAt(i);
                    }
                    
                    const mimeType = format === 'mp3' ? 'audio/mpeg' : 'audio/wav';
                    const blob = new Blob([bytes], { type: mimeType });
                    const audioUrl = URL.createObjectURL(blob);
                    
                    // Store for download and show in sidebar player
                    lastAudioBlob = blob;
                    audioPlayerContainer.classList.remove('hidden');
                    aiAudioPlayer.src = audioUrl;
                    
                    // Use the existing audio player
                    const audio = new Audio(audioUrl);
                    
                    // Pause VAD while playing
                    isAISpeaking = true;
                    stopBrowserTranscription();
                    console.log('[Groklexa] Server audio playing - pausing VAD & transcription');
                    
                    audio.onended = () => {
                        isAISpeaking = false;
                        browserTranscriptBuffer = '';
                        sileroAudioChunks = [];  // Clear any AI speech captured by recorder
                        if (wakeWordState === 'active' && currentApiConfig?.mode === 'separate' && 
                            currentApiConfig?.transcription?.provider === 'browser') {
                            startBrowserTranscription();
                        }
                        console.log('[Groklexa] Server audio complete - resuming VAD & transcription (buffer cleared)');
                        // Don't revoke URL - keep it for the sidebar player
                        resolve();
                    };
                    
                    audio.onerror = (e) => {
                        isAISpeaking = false;
                        sileroAudioChunks = [];  // Clear any AI speech captured by recorder
                        console.error('[Groklexa] Audio playback error:', e);
                        reject(new Error('Audio playback failed'));
                    };
                    
                    audio.play();
                    
                } catch (e) {
                    reject(e);
                }
            });
        }
        
        // Browser-based speech synthesis
        function synthesizeWithWebSpeech(text) {
            return new Promise((resolve, reject) => {
                if (!('speechSynthesis' in window)) {
                    reject(new Error('Speech synthesis not supported'));
                    return;
                }
                
                // Cancel any ongoing speech
                window.speechSynthesis.cancel();
                
                const utterance = new SpeechSynthesisUtterance(text);
                utterance.lang = 'en-US';
                utterance.rate = 1.0;
                utterance.pitch = 1.0;
                
                // Try to find a good voice
                const voices = window.speechSynthesis.getVoices();
                const preferredVoice = voices.find(v => v.name.includes('Samantha') || v.name.includes('Google')) 
                                    || voices.find(v => v.lang.startsWith('en'));
                if (preferredVoice) {
                    utterance.voice = preferredVoice;
                }
                
                utterance.onend = () => {
                    console.log('[Groklexa] Speech synthesis complete');
                    resolve();
                };
                
                utterance.onerror = (event) => {
                    isAISpeaking = false;
                    sileroAudioChunks = [];  // Clear any AI speech captured by recorder
                    // Resume browser transcription and clear any garbage it picked up
                    browserTranscriptBuffer = '';
                    startBrowserTranscription();
                    console.error('[Groklexa] Speech synthesis error:', event.error);
                    reject(new Error('Speech synthesis error: ' + event.error));
                };
                
                utterance.onstart = () => {
                    // Pause VAD and browser transcription while speaking
                    isAISpeaking = true;
                    stopBrowserTranscription();  // Stop transcribing our own speech
                    console.log('[Groklexa] Browser synthesis started - pausing VAD & transcription');
                };
                
                utterance.onend = () => {
                    isAISpeaking = false;
                    sileroAudioChunks = [];  // Clear any AI speech captured by recorder
                    // Resume browser transcription with clean buffer
                    browserTranscriptBuffer = '';
                    if (wakeWordState === 'active' && currentApiConfig?.mode === 'separate' && 
                        currentApiConfig?.transcription?.provider === 'browser') {
                        startBrowserTranscription();
                    }
                    console.log('[Groklexa] Speech synthesis complete - resuming VAD & transcription (buffer cleared)');
                    resolve();
                };
                
                window.speechSynthesis.speak(utterance);
            });
        }

        // ========== EVENT HANDLERS ==========
        
        vadToggle.addEventListener('change', async () => {
            if (vadToggle.checked) {
                isVadActive = true;
                const success = await startVAD();
                if (!success) {
                    vadToggle.checked = false;
                    isVadActive = false;
                }
            } else {
                isVadActive = false;
                stopVAD();
                hideStatus();
            }
        });
        
        // Earcons and fillers toggles
        const earconsToggle = document.getElementById('earconsToggle');
        const fillersToggle = document.getElementById('fillersToggle');
        
        // Initialize toggle states from localStorage
        earconsToggle.checked = earconsEnabled;
        fillersToggle.checked = fillersEnabled;
        
        earconsToggle.addEventListener('change', () => {
            earconsEnabled = earconsToggle.checked;
            localStorage.setItem('earconsEnabled', earconsEnabled);
            console.log(`[Groklexa] Earcons ${earconsEnabled ? 'enabled' : 'disabled'}`);
        });
        
        fillersToggle.addEventListener('change', () => {
            fillersEnabled = fillersToggle.checked;
            localStorage.setItem('fillersEnabled', fillersEnabled);
            console.log(`[Groklexa] Fillers ${fillersEnabled ? 'enabled' : 'disabled'}`);
        });
        
        // ========== PERSONA MANAGEMENT ==========
        
        const personaSelect = document.getElementById('personaSelect');
        const personaPrompt = document.getElementById('personaPrompt');
        const personaEditBtn = document.getElementById('personaEditBtn');
        const personaAddBtn = document.getElementById('personaAddBtn');
        const savePromptBtn = document.getElementById('savePromptBtn');
        const saveToolsBtn = document.getElementById('saveToolsBtn');
        
        // Tool permission checkboxes
        const toolDateTime = document.getElementById('toolDateTime');
        const toolWeather = document.getElementById('toolWeather');
        const toolTimer = document.getElementById('toolTimer');
        const toolSystemInfo = document.getElementById('toolSystemInfo');
        const toolEscalate = document.getElementById('toolEscalate');
        const toolSearchX = document.getElementById('toolSearchX');
        const toolSearchWeb = document.getElementById('toolSearchWeb');
        
        let currentPersonaId = 'default';
        
        // Helper function to show config status messages
        function showConfigStatus(message, type = 'success') {
            const configStatus = document.getElementById('configStatus');
            if (!configStatus) return;
            
            configStatus.style.display = 'block';
            configStatus.className = `config-status ${type}`;
            configStatus.textContent = message;
            
            setTimeout(() => {
                configStatus.style.display = 'none';
            }, 3000);
        }
        
        async function loadPersonas() {
            try {
                const response = await fetch('/api/personas');
                const data = await response.json();
                
                if (data.success && data.personas) {
                    personaSelect.innerHTML = data.personas
                        .map(p => `<option value="${p.id}" ${p.active ? 'selected' : ''}>${p.name}</option>`)
                        .join('');
                    
                    currentPersonaId = data.active_persona || 'default';
                    console.log('[Groklexa] Loaded personas:', data.personas.length);
                }
            } catch (e) {
                console.error('[Groklexa] Failed to load personas:', e);
            }
        }
        
        async function switchPersona(personaId) {
            try {
                const response = await fetch('/api/personas/switch', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ persona_id: personaId })
                });
                
                const data = await response.json();
                
                if (data.success) {
                    currentPersonaId = personaId;
                    console.log('[Groklexa] Switched to persona:', data.active?.name);
                    
                    // Reload full config to update all UI elements
                    await loadApiConfig();
                    
                    // Update localStorage key for chat history
                    loadHistory();
                    
                    showConfigStatus('Persona switched!', 'success');
                } else {
                    showConfigStatus(data.error || 'Failed to switch persona', 'error');
                }
            } catch (e) {
                console.error('[Groklexa] Failed to switch persona:', e);
                showConfigStatus('Failed to switch persona', 'error');
            }
        }
        
        async function savePersonaPrompt() {
            try {
                const prompt = personaPrompt.value;
                
                const response = await fetch(`/api/personas/${currentPersonaId}`, {
                    method: 'PUT',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ prompt })
                });
                
                const data = await response.json();
                
                if (data.success) {
                    showConfigStatus('Prompt saved!', 'success');
                } else {
                    showConfigStatus(data.error || 'Failed to save prompt', 'error');
                }
            } catch (e) {
                console.error('[Groklexa] Failed to save prompt:', e);
                showConfigStatus('Failed to save prompt', 'error');
            }
        }
        
        async function createNewPersona() {
            const name = prompt('Enter name for new persona:');
            if (!name) return;
            
            try {
                const response = await fetch('/api/personas', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        persona: {
                            name: name,
                            prompt: `You are ${name}, an AI assistant.`
                        }
                    })
                });
                
                const data = await response.json();
                
                if (data.success) {
                    // Reload personas and switch to the new one
                    await loadPersonas();
                    await switchPersona(data.persona_id);
                    showConfigStatus(`Created persona: ${name}`, 'success');
                } else {
                    showConfigStatus(data.error || 'Failed to create persona', 'error');
                }
            } catch (e) {
                console.error('[Groklexa] Failed to create persona:', e);
                showConfigStatus('Failed to create persona', 'error');
            }
        }
        
        // Persona event listeners
        personaSelect.addEventListener('change', (e) => {
            switchPersona(e.target.value);
        });
        
        savePromptBtn.addEventListener('click', savePersonaPrompt);
        personaAddBtn.addEventListener('click', createNewPersona);
        
        // Save tool permissions
        async function saveToolPermissions() {
            try {
                const tools = {
                    get_current_datetime: toolDateTime.checked,
                    get_current_weather: toolWeather.checked,
                    set_timer: toolTimer.checked,
                    set_reminder: toolTimer.checked,   // Same toggle as set_timer
                    list_timers: toolTimer.checked,    // Same toggle as set_timer
                    cancel_timer: toolTimer.checked,   // Same toggle as set_timer
                    get_system_info: toolSystemInfo.checked,
                    escalate_thinking: toolEscalate.checked,
                    search_x: toolSearchX.checked,
                    search_web: toolSearchWeb.checked
                };
                
                const response = await fetch(`/api/personas/${currentPersonaId}`, {
                    method: 'PUT',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ tools })
                });
                
                const data = await response.json();
                
                if (data.success) {
                    showConfigStatus('Tool permissions saved!', 'success');
                    console.log('[Groklexa] Tool permissions saved:', tools);
                } else {
                    showConfigStatus(data.error || 'Failed to save tools', 'error');
                }
            } catch (e) {
                console.error('[Groklexa] Failed to save tools:', e);
                showConfigStatus('Failed to save tool permissions', 'error');
            }
        }
        
        saveToolsBtn.addEventListener('click', saveToolPermissions);
        
        personaEditBtn.addEventListener('click', () => {
            // Toggle prompt details open
            const details = document.querySelector('.prompt-details');
            details.open = !details.open;
        });
        
        // ========== API CONFIGURATION ==========
        
        // Global config cache for routing decisions
        let currentApiConfig = null;
        
        const apiModeSingle = document.getElementById('apiModeSingle');
        const apiModeSeparate = document.getElementById('apiModeSeparate');
        const singleApiConfig = document.getElementById('singleApiConfig');
        const separateApiConfig = document.getElementById('separateApiConfig');
        const configStatus = document.getElementById('configStatus');
        
        // Provider default URLs
        const PROVIDER_URLS = {
            xai_realtime: 'wss://api.x.ai/v1/realtime',
            grok: 'https://api.x.ai/v1/chat/completions',
            anthropic: 'https://api.anthropic.com/v1/messages',
            openai: 'https://api.openai.com/v1/chat/completions',
            whisper: 'https://api.openai.com/v1/audio/transcriptions',
            elevenlabs: 'https://api.elevenlabs.io/v1/text-to-speech',
            ollama: 'http://localhost:11434/v1/chat/completions',
            google: 'https://speech.googleapis.com/v1/speech:recognize',
            browser: '',
            custom: ''
        };
        
        // Toggle between single and separate API modes
        function updateApiModeUI() {
            if (apiModeSingle.checked) {
                singleApiConfig.classList.remove('hidden-section');
                separateApiConfig.classList.add('hidden-section');
            } else {
                singleApiConfig.classList.add('hidden-section');
                separateApiConfig.classList.remove('hidden-section');
            }
        }
        
        apiModeSingle.addEventListener('change', updateApiModeUI);
        apiModeSeparate.addEventListener('change', updateApiModeUI);
        
        // Update URL when provider changes
        function setupProviderUrlSync(providerSelect, urlInput, section) {
            providerSelect.addEventListener('change', () => {
                const provider = providerSelect.value;
                if (provider !== 'custom' && PROVIDER_URLS[provider]) {
                    urlInput.value = PROVIDER_URLS[provider];
                }
                
                // Hide URL/Auth fields for browser provider
                const urlField = document.getElementById(`${section}UrlField`);
                const authField = document.getElementById(`${section}AuthField`);
                if (urlField && authField) {
                    if (provider === 'browser') {
                        urlField.style.display = 'none';
                        authField.style.display = 'none';
                    } else {
                        urlField.style.display = 'block';
                        authField.style.display = 'flex';
                    }
                }
                
                detectModelFromUrl(urlInput.value, section);
            });
            
            urlInput.addEventListener('input', () => {
                detectModelFromUrl(urlInput.value, section);
            });
        }
        
        // Detect model from URL
        function detectModelFromUrl(url, section) {
            if (!url) return;
            
            const patterns = [
                [/grok-4/i, 'Grok 4'],
                [/grok-3/i, 'Grok 3'],
                [/grok-2/i, 'Grok 2'],
                [/claude-3-opus/i, 'Claude 3 Opus'],
                [/claude-3-sonnet/i, 'Claude 3 Sonnet'],
                [/claude-sonnet-4/i, 'Claude Sonnet 4'],
                [/claude-3-haiku/i, 'Claude 3 Haiku'],
                [/gpt-4/i, 'GPT-4'],
                [/gpt-3\.5/i, 'GPT-3.5'],
                [/whisper/i, 'Whisper'],
                [/llama/i, 'LLaMA'],
            ];
            
            let detected = null;
            for (const [pattern, name] of patterns) {
                if (pattern.test(url)) {
                    detected = name;
                    break;
                }
            }
            
            const modelSpan = document.getElementById(`${section}DetectedModel`);
            if (modelSpan) {
                if (detected) {
                    modelSpan.textContent = detected;
                    modelSpan.style.display = 'inline';
                } else {
                    modelSpan.style.display = 'none';
                }
            }
        }
        
        // Setup provider sync for each section
        setupProviderUrlSync(
            document.getElementById('singleProvider'),
            document.getElementById('singleUrl'),
            'single'
        );
        setupProviderUrlSync(
            document.getElementById('transcriptionProvider'),
            document.getElementById('transcriptionUrl'),
            'transcription'
        );
        
        // Transcription provider change handler
        const transcriptionProvider = document.getElementById('transcriptionProvider');
        const whisperModelField = document.querySelector('.whisper-model-field');
        const transcriptionUrlField = document.querySelector('.transcription-url-field');
        const transcriptionAuthField = document.getElementById('transcriptionAuth')?.closest('.api-field-row');
        
        function updateTranscriptionUI() {
            const provider = transcriptionProvider.value;
            
            // Show/hide whisper model selector
            if (provider === 'local_whisper') {
                whisperModelField.style.display = 'block';
                if (transcriptionUrlField) transcriptionUrlField.style.display = 'none';
                if (transcriptionAuthField) transcriptionAuthField.style.display = 'none';
            } else if (provider === 'browser') {
                whisperModelField.style.display = 'none';
                if (transcriptionUrlField) transcriptionUrlField.style.display = 'none';
                if (transcriptionAuthField) transcriptionAuthField.style.display = 'none';
            } else {
                whisperModelField.style.display = 'none';
                if (transcriptionUrlField) transcriptionUrlField.style.display = 'block';
                if (transcriptionAuthField) transcriptionAuthField.style.display = 'flex';
            }
        }
        
        transcriptionProvider.addEventListener('change', updateTranscriptionUI);
        updateTranscriptionUI();
        
        // Load Whisper model
        async function loadWhisperModel() {
            const size = document.getElementById('whisperModelSize').value;
            const btn = document.getElementById('loadWhisperBtn');
            
            btn.textContent = 'Loading...';
            btn.disabled = true;
            
            try {
                const response = await fetch('/api/whisper/load', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ size })
                });
                
                const data = await response.json();
                
                if (data.success) {
                    btn.textContent = '‚úì Loaded';
                    btn.className = 'test-btn success';
                } else {
                    btn.textContent = '‚úó Failed';
                    btn.className = 'test-btn error';
                    console.error('[Groklexa] Whisper load error:', data.error);
                }
            } catch (e) {
                btn.textContent = '‚úó Error';
                btn.className = 'test-btn error';
                console.error('[Groklexa] Whisper load error:', e);
            }
            
            setTimeout(() => {
                btn.textContent = 'Load Model';
                btn.className = 'test-btn';
                btn.disabled = false;
            }, 3000);
        }
        
        // Make loadWhisperModel available globally
        window.loadWhisperModel = loadWhisperModel;
        
        setupProviderUrlSync(
            document.getElementById('inferenceProvider'),
            document.getElementById('inferenceUrl'),
            'inference'
        );
        
        // Model selector for inference
        const inferenceProvider = document.getElementById('inferenceProvider');
        const inferenceModel = document.getElementById('inferenceModel');
        const inferenceUrlField = document.querySelector('.inference-url-field');
        const inferenceAuthField = document.querySelector('.inference-auth-field');
        
        // Pending model value to set after models are fetched
        let pendingInferenceModel = null;
        let pendingSynthesisVoice = null;
        let pendingSingleVoice = null;
        
        // Fallback models if API fetch fails
        const FALLBACK_MODELS = {
            grok: [
                { id: 'grok-4', name: 'Grok 4' },
                { id: 'grok-3', name: 'Grok 3' },
                { id: 'grok-3-fast', name: 'Grok 3 Fast' }
            ],
            anthropic: [
                { id: 'claude-sonnet-4-20250514', name: 'Claude Sonnet 4' },
                { id: 'claude-3-5-sonnet-20241022', name: 'Claude 3.5 Sonnet' }
            ],
            openai: [
                { id: 'gpt-4o', name: 'GPT-4o' },
                { id: 'gpt-4o-mini', name: 'GPT-4o Mini' }
            ],
            ollama: [
                { id: 'llama3.2', name: 'Llama 3.2' }
            ],
            llama_cpp: [
                { id: 'default', name: 'Loaded Model (default)' }
            ],
            custom: []
        };
        
        async function updateInferenceModels() {
            const provider = inferenceProvider.value;
            
            // Show custom model input for custom provider
            if (provider === 'custom') {
                inferenceModel.style.display = 'none';
                return;
            }
            
            inferenceModel.style.display = 'block';
            inferenceModel.innerHTML = '<option value="">Loading models...</option>';
            
            // Show/hide URL for local providers (usually localhost)
            if (provider === 'ollama') {
                document.getElementById('inferenceUrl').value = 'http://localhost:11434/v1/chat/completions';
            } else if (provider === 'llama_cpp') {
                document.getElementById('inferenceUrl').value = 'http://localhost:8080/v1/chat/completions';
            }
            
            try {
                const response = await fetch(`/api/models/${provider}`);
                const data = await response.json();
                
                if (data.success && data.models && data.models.length > 0) {
                    inferenceModel.innerHTML = data.models
                        .map(m => `<option value="${m.id}">${m.name}</option>`)
                        .join('');
                    console.log(`[Groklexa] Loaded ${data.models.length} models for ${provider}`);
                } else {
                    // Use fallback
                    const fallback = FALLBACK_MODELS[provider] || [];
                    inferenceModel.innerHTML = fallback
                        .map(m => `<option value="${m.id}">${m.name}</option>`)
                        .join('');
                    if (fallback.length === 0) {
                        inferenceModel.innerHTML = '<option value="">No models available</option>';
                    }
                    console.log(`[Groklexa] Using fallback models for ${provider}`);
                }
            } catch (e) {
                console.error(`[Groklexa] Failed to fetch models for ${provider}:`, e);
                const fallback = FALLBACK_MODELS[provider] || [];
                inferenceModel.innerHTML = fallback
                    .map(m => `<option value="${m.id}">${m.name}</option>`)
                    .join('');
            }
            
            // Restore pending model value if set
            if (pendingInferenceModel) {
                console.log(`[Groklexa] Attempting to restore model: ${pendingInferenceModel}`);
                console.log(`[Groklexa] Available options:`, Array.from(inferenceModel.options).map(o => o.value));
                inferenceModel.value = pendingInferenceModel;
                console.log(`[Groklexa] After setting, value is: ${inferenceModel.value}`);
                if (inferenceModel.value !== pendingInferenceModel) {
                    console.warn(`[Groklexa] Model restore FAILED - value mismatch`);
                }
                pendingInferenceModel = null;
            }
        }
        
        inferenceProvider.addEventListener('change', updateInferenceModels);
        // Don't call updateInferenceModels() here - let loadApiConfig() trigger it
        // This ensures pendingInferenceModel is set before models are fetched
        
        setupProviderUrlSync(
            document.getElementById('synthesisProvider'),
            document.getElementById('synthesisUrl'),
            'synthesis'
        );
        
        // Voice selector for synthesis
        const synthesisProvider = document.getElementById('synthesisProvider');
        const synthesisVoice = document.getElementById('synthesisVoice');
        const synthesisUrlField = document.querySelector('.synthesis-url-field');
        const synthesisAuthField = document.querySelector('.synthesis-auth-field');
        
        async function updateSynthesisVoices() {
            const provider = synthesisProvider.value;
            synthesisVoice.innerHTML = '<option value="">Loading voices...</option>';
            
            // Show/hide URL and Auth fields based on provider
            if (provider === 'browser' || provider === 'edge_tts' || provider === 'chatterbox') {
                synthesisUrlField.style.display = 'none';
                synthesisAuthField.style.display = 'none';
            } else {
                synthesisUrlField.style.display = 'block';
                synthesisAuthField.style.display = 'flex';
            }
            
            if (provider === 'browser') {
                // Get browser voices
                const voices = window.speechSynthesis.getVoices();
                if (voices.length === 0) {
                    // Voices might not be loaded yet
                    await new Promise(resolve => {
                        window.speechSynthesis.onvoiceschanged = resolve;
                        setTimeout(resolve, 1000);
                    });
                }
                const browserVoices = window.speechSynthesis.getVoices();
                synthesisVoice.innerHTML = browserVoices
                    .filter(v => v.lang.startsWith('en'))
                    .map(v => `<option value="${v.name}">${v.name} (${v.lang})</option>`)
                    .join('');
                return;
            }
            
            try {
                const response = await fetch(`/api/voices/${provider}`);
                const data = await response.json();
                
                if (data.success && data.voices.length > 0) {
                    synthesisVoice.innerHTML = data.voices
                        .map(v => `<option value="${v.id}">${v.name}</option>`)
                        .join('');
                    console.log(`[Groklexa] Loaded ${data.voices.length} voices for ${provider}`);
                    
                    // Restore pending voice if it exists
                    if (pendingSynthesisVoice) {
                        console.log(`[Groklexa] Attempting to restore voice: ${pendingSynthesisVoice}`);
                        synthesisVoice.value = pendingSynthesisVoice;
                        console.log(`[Groklexa] After setting, voice is: ${synthesisVoice.value}`);
                        pendingSynthesisVoice = null;
                    }
                } else {
                    synthesisVoice.innerHTML = '<option value="">No voices available</option>';
                }
            } catch (e) {
                console.error('[Groklexa] Failed to fetch voices:', e);
                synthesisVoice.innerHTML = '<option value="">Error loading voices</option>';
            }
        }
        
        synthesisProvider.addEventListener('change', updateSynthesisVoices);
        
        // Initial voice load
        updateSynthesisVoices();
        
        // Load config from server
        async function loadApiConfig() {
            try {
                const response = await fetch('/api/config');
                const data = await response.json();
                
                if (data.success && data.config) {
                    const fullConfig = data.config;
                    
                    // Use the active persona's flattened config
                    const config = fullConfig.active || fullConfig;
                    
                    // Update persona UI
                    if (fullConfig.active_persona) {
                        currentPersonaId = fullConfig.active_persona;
                        personaSelect.value = currentPersonaId;
                    }
                    
                    // Load persona's custom prompt
                    if (config.prompt) {
                        personaPrompt.value = config.prompt;
                    }
                    
                    // Load persona's tool permissions
                    if (config.tools) {
                        toolDateTime.checked = config.tools.get_current_datetime !== false;
                        toolWeather.checked = config.tools.get_current_weather !== false;
                        toolTimer.checked = config.tools.set_timer !== false;
                        toolSystemInfo.checked = config.tools.get_system_info !== false;
                        toolEscalate.checked = config.tools.escalate_thinking !== false;
                        toolSearchX.checked = config.tools.search_x !== false;
                        toolSearchWeb.checked = config.tools.search_web !== false;
                        console.log('[Groklexa] Loaded tool permissions:', config.tools);
                    }
                    
                    // Set mode
                    if (config.mode === 'separate') {
                        apiModeSeparate.checked = true;
                    } else {
                        apiModeSingle.checked = true;
                    }
                    updateApiModeUI();
                    
                    // Populate single API config
                    if (config.single) {
                        document.getElementById('singleProvider').value = config.single.provider || 'xai_realtime';
                        document.getElementById('singleUrl').value = config.single.url || '';
                        document.getElementById('singleAuth').value = config.single.auth || '';
                        if (config.single.voice) {
                            document.getElementById('singleVoice').value = config.single.voice;
                        }
                        if (config.single.detected_model) {
                            const el = document.getElementById('singleDetectedModel');
                            el.textContent = config.single.detected_model;
                            el.style.display = 'inline';
                        }
                    }
                    
                    // Populate separate API configs
                    ['transcription', 'inference', 'synthesis'].forEach(section => {
                        if (config[section]) {
                            const providerEl = document.getElementById(`${section}Provider`);
                            const urlEl = document.getElementById(`${section}Url`);
                            const authEl = document.getElementById(`${section}Auth`);
                            const voiceEl = document.getElementById(`${section}Voice`);
                            
                            if (providerEl) providerEl.value = config[section].provider || '';
                            if (urlEl) urlEl.value = config[section].url || '';
                            if (authEl) authEl.value = config[section].auth || '';
                            
                            if (config[section].detected_model) {
                                const modelEl = document.getElementById(`${section}DetectedModel`);
                                if (modelEl) {
                                    modelEl.textContent = config[section].detected_model;
                                    modelEl.style.display = 'inline';
                                }
                            }
                            
                            // Set model for inference - store BEFORE triggering change event
                            // (change event triggers async model fetch, which will apply this value)
                            if (section === 'inference' && config[section].model) {
                                pendingInferenceModel = config[section].model;
                                console.log(`[Groklexa] Pending inference model: ${config[section].model}`);
                            }
                            
                            // Set voice for synthesis - store BEFORE triggering change event
                            if (section === 'synthesis' && config[section].voice) {
                                pendingSynthesisVoice = config[section].voice;
                                console.log(`[Groklexa] Pending synthesis voice: ${config[section].voice}`);
                            }
                            
                            // Trigger provider change to update visibility and voices
                            if (providerEl) {
                                providerEl.dispatchEvent(new Event('change'));
                            }
                        }
                    });
                    
                    // Store config globally for routing decisions
                    currentApiConfig = config;
                    console.log('[Groklexa] API config loaded:', config.mode, 'mode');
                    
                    // Load persona fillers in background (don't await - let it happen async)
                    if (currentPersonaId) {
                        loadPersonaFillers(currentPersonaId).then(() => {
                            console.log('[Groklexa] Persona fillers ready');
                        });
                    }
                }
            } catch (e) {
                console.error('[Groklexa] Failed to load API config:', e);
            }
        }
        
        // Save config to server
        async function saveApiConfig() {
            const config = {
                mode: apiModeSingle.checked ? 'single' : 'separate',
                single: {
                    provider: document.getElementById('singleProvider').value,
                    url: document.getElementById('singleUrl').value,
                    auth: document.getElementById('singleAuth').value,
                    voice: document.getElementById('singleVoice').value,
                    protocol: document.getElementById('singleProvider').value
                },
                transcription: {
                    provider: document.getElementById('transcriptionProvider').value,
                    url: document.getElementById('transcriptionUrl').value,
                    auth: document.getElementById('transcriptionAuth').value,
                    protocol: document.getElementById('transcriptionProvider').value
                },
                inference: {
                    provider: document.getElementById('inferenceProvider').value,
                    url: document.getElementById('inferenceUrl').value,
                    auth: document.getElementById('inferenceAuth').value,
                    model: document.getElementById('inferenceModel').value,
                    protocol: document.getElementById('inferenceProvider').value
                },
                synthesis: {
                    provider: document.getElementById('synthesisProvider').value,
                    url: document.getElementById('synthesisUrl').value,
                    auth: document.getElementById('synthesisAuth').value,
                    voice: document.getElementById('synthesisVoice').value,
                    protocol: document.getElementById('synthesisProvider').value
                }
            };
            
            try {
                const response = await fetch('/api/config', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(config)
                });
                
                const data = await response.json();
                
                configStatus.style.display = 'block';
                if (data.success) {
                    configStatus.className = 'config-status success';
                    configStatus.textContent = 'Configuration saved!';
                } else {
                    configStatus.className = 'config-status error';
                    configStatus.textContent = 'Error: ' + data.error;
                }
                
                setTimeout(() => {
                    configStatus.style.display = 'none';
                }, 3000);
                
            } catch (e) {
                configStatus.style.display = 'block';
                configStatus.className = 'config-status error';
                configStatus.textContent = 'Error: ' + e.message;
            }
        }
        
        // Test connection
        async function testConnection(section) {
            const btn = event.target;
            btn.disabled = true;
            btn.textContent = 'Testing...';
            
            let provider, url, auth;
            
            if (section === 'single') {
                provider = document.getElementById('singleProvider').value;
                url = document.getElementById('singleUrl').value;
                auth = document.getElementById('singleAuth').value;
            } else {
                provider = document.getElementById(`${section}Provider`).value;
                url = document.getElementById(`${section}Url`).value;
                auth = document.getElementById(`${section}Auth`).value;
            }
            
            try {
                const response = await fetch('/api/config/test', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ section, provider, url, auth, protocol: provider })
                });
                
                const data = await response.json();
                
                btn.textContent = data.success ? '‚úì OK' : '‚úó Fail';
                btn.className = 'test-btn ' + (data.success ? 'success' : 'error');
                
                if (data.detected_model) {
                    const modelEl = document.getElementById(`${section}DetectedModel`);
                    if (modelEl) {
                        modelEl.textContent = data.detected_model;
                        modelEl.style.display = 'inline';
                    }
                }
                
            } catch (e) {
                btn.textContent = '‚úó Error';
                btn.className = 'test-btn error';
            }
            
            setTimeout(() => {
                btn.disabled = false;
                btn.textContent = 'Test';
                btn.className = 'test-btn';
            }, 3000);
        }
        
        // ========== TIMER POLLING ==========
        
        let timerPollInterval = null;
        
        async function checkTimers() {
            try {
                const response = await fetch('/api/timers');
                const data = await response.json();
                
                if (data.success && data.fired && data.fired.length > 0) {
                    for (const timer of data.fired) {
                        console.log('[Groklexa] Timer fired:', timer.id, timer.message);
                        await playTimerAlarm(timer);
                        
                        // Acknowledge the timer
                        await fetch(`/api/timers/${timer.id}/acknowledge`, { method: 'POST' });
                    }
                }
            } catch (e) {
                console.error('[Groklexa] Timer check error:', e);
            }
        }
        
        async function playTimerAlarm(timer) {
            const message = timer.message || 'Timer complete';
            const alarmText = `Hey! Your ${formatDuration(timer.minutes)} timer is done. ${message}`;
            
            console.log('[Groklexa] Playing timer alarm:', alarmText);
            
            // Use the synthesis API to speak the alarm
            try {
                const response = await fetch('/api/synthesize', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ text: alarmText })
                });
                
                const data = await response.json();
                
                if (data.success && data.audio_base64) {
                    // Play server-generated audio
                    const audioData = atob(data.audio_base64);
                    const audioArray = new Uint8Array(audioData.length);
                    for (let i = 0; i < audioData.length; i++) {
                        audioArray[i] = audioData.charCodeAt(i);
                    }
                    const blob = new Blob([audioArray], { type: `audio/${data.audio_format || 'wav'}` });
                    const audioUrl = URL.createObjectURL(blob);
                    
                    const audio = new Audio(audioUrl);
                    audio.play();
                } else if (data.use_browser) {
                    // Use browser speech synthesis
                    const utterance = new SpeechSynthesisUtterance(alarmText);
                    speechSynthesis.speak(utterance);
                }
            } catch (e) {
                console.error('[Groklexa] Failed to play timer alarm:', e);
                // Fallback to browser speech
                const utterance = new SpeechSynthesisUtterance(alarmText);
                speechSynthesis.speak(utterance);
            }
        }
        
        function formatDuration(minutes) {
            if (minutes >= 60) {
                const hours = Math.floor(minutes / 60);
                const mins = Math.floor(minutes % 60);
                return mins > 0 ? `${hours} hour${hours !== 1 ? 's' : ''} and ${mins} minute${mins !== 1 ? 's' : ''}` : `${hours} hour${hours !== 1 ? 's' : ''}`;
            } else if (minutes >= 1) {
                return `${Math.floor(minutes)} minute${minutes !== 1 ? 's' : ''}`;
            } else {
                return `${Math.floor(minutes * 60)} second${minutes * 60 !== 1 ? 's' : ''}`;
            }
        }
        
        function startTimerPolling() {
            if (!timerPollInterval) {
                timerPollInterval = setInterval(checkTimers, 3000);  // Check every 3 seconds
                console.log('[Groklexa] Timer polling started');
            }
        }
        
        function stopTimerPolling() {
            if (timerPollInterval) {
                clearInterval(timerPollInterval);
                timerPollInterval = null;
                console.log('[Groklexa] Timer polling stopped');
            }
        }
        
        // ========== DEEP THINKING POLLING ==========
        
        let thoughtPollInterval = null;
        
        async function checkPendingThoughts() {
            try {
                const response = await fetch('/api/escalation/pending');
                const data = await response.json();
                
                if (data.success && data.pending && data.pending.length > 0) {
                    for (const thought of data.pending) {
                        console.log('[Groklexa] Deep thinking complete:', thought.id, thought.query);
                        await announceThought(thought);
                        
                        // Acknowledge the thought
                        await fetch(`/api/escalation/pending/${thought.id}/acknowledge`, { method: 'POST' });
                    }
                }
            } catch (e) {
                console.error('[Groklexa] Thought check error:', e);
            }
        }
        
        async function announceThought(thought) {
            // Wait for any active synthesis to complete
            while (isAISpeaking || isProcessing) {
                console.log('[Groklexa] Waiting for synthesis to complete before announcing thought...');
                await new Promise(resolve => setTimeout(resolve, 1000));
            }
            
            // Create a summary for voice announcement
            const summary = thought.response.substring(0, 500);
            const announcementText = `I've finished thinking deeply about ${thought.query.substring(0, 50)}. Here's what I found: ${summary}`;
            
            console.log('[Groklexa] Announcing thought:', thought.id);
            showStatus('üß† Deep thinking complete!', 'success');
            
            // Add to chat history
            addToHistory('assistant', `[Deep Analysis of "${thought.query}"]\n\n${thought.response}`);
            
            // Speak the summary using synthesis API
            try {
                const response = await fetch('/api/synthesize', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ text: announcementText })
                });
                
                if (response.ok) {
                    const data = await response.json();
                    if (data.audio) {
                        await playServerAudio(data.audio, data.format || 'wav');
                    }
                }
            } catch (e) {
                console.error('[Groklexa] Failed to announce thought:', e);
                // Fallback to browser speech
                if ('speechSynthesis' in window) {
                    const utterance = new SpeechSynthesisUtterance(announcementText);
                    speechSynthesis.speak(utterance);
                }
            }
        }
        
        function startThoughtPolling() {
            if (!thoughtPollInterval) {
                thoughtPollInterval = setInterval(checkPendingThoughts, 5000);  // Check every 5 seconds
                console.log('[Groklexa] Thought polling started');
            }
        }
        
        function stopThoughtPolling() {
            if (thoughtPollInterval) {
                clearInterval(thoughtPollInterval);
                thoughtPollInterval = null;
                console.log('[Groklexa] Thought polling stopped');
            }
        }
        
        // Load personas and config on page load
        async function initializeApp() {
            showStatus('‚è≥ Loading configuration...', 'info');
            
            await loadPersonas();
            await loadApiConfig();
            
            showStatus('‚è≥ Initializing audio systems...', 'info');
            
            // Start polling
            startTimerPolling();
            startThoughtPolling();
            
            // Wait a moment for audio context to be ready
            await new Promise(resolve => setTimeout(resolve, 500));
            
            showStatus('‚úÖ Ready - toggle Listen to begin', 'success');
            console.log('[Groklexa] Initialization complete');
        }
        initializeApp();
    </script>
</body>
</html>
